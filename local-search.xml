<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Principles By Ray Dalio: Short Summary</title>
    <link href="/2021/10/13/principles/"/>
    <url>/2021/10/13/principles/</url>
    
    <content type="html"><![CDATA[<p>In Principles, Ray Dalio lays down the rules and frameworks he uses to navigate his life. The book explores truth-seeking, decision-making, and the implementation of systems to achieve success. Afterward, Ray goes over the management principles he used to build his multibillion-dollar hedge fund, Bridgewater.</p><h2 id="Fundamental-Life-Principles"><a href="#Fundamental-Life-Principles" class="headerlink" title="Fundamental Life Principles"></a>Fundamental Life Principles</h2><p><strong>Ray Dalio’s 5 guiding principles for work:</strong></p><ol><li><strong>Working for what he wanted</strong>, not for what others wanted him to do</li><li><strong>Coming up with the best independent opinions</strong> he could conveive</li><li><strong>Stress-testing his opinions</strong> by having the smartest people finding the flaws in his thinking</li><li>Being wary about <strong>overconfidence</strong>, and good at not knowing</li><li><strong>Embracing reality</strong>, experiencing the results of his decisions, and reflecting on what he did to improve.</li></ol><blockquote><p>While most others seem to believe that having answers is better than having questions, I believe that having questions is better than having answers because it leads to more learning.</p></blockquote><h3 id="Embrace-Reality-and-Deal-With-It"><a href="#Embrace-Reality-and-Deal-With-It" class="headerlink" title="Embrace Reality and Deal With It"></a>Embrace Reality and Deal With It</h3><p>The quality of your life depends on the quality of the decisions you make.</p><p><strong>Hyperrealism: accepting the reality as it is rather than wishing it was different.</strong> Understanding the reality allows you to learn how to work with them rather than fight with them, which leads to greater success.</p><blockquote><p>Truth - more precisely, an accurate understanding of reality - is the essential foundation for producing good outcomes.</p></blockquote><p>Don’t get hung up on your views about how things should be because then you’ll miss out on learning how they really are.</p><h3 id="The-Personal-Evolutionary-Process"><a href="#The-Personal-Evolutionary-Process" class="headerlink" title="The Personal Evolutionary Process"></a>The Personal Evolutionary Process</h3><p>Evolution, which is the natural movement towards better adaptation, is the greatest single force in the universe. Pursuing self-interest in harmony with the laws of the universe and contributing to evolution is universally rewarded.</p><p>The most important quality that differentiates successful people from unsuccessful people is our capacity to learn and adapt to things that we value.</p><p><strong>Reality + Dreams + Determination = A Successful Life</strong></p><blockquote><p>The people who really change the world are the ones who see what’s possible and figure out how to make that happen.</p></blockquote><h3 id="Your-Most-Important-Choices"><a href="#Your-Most-Important-Choices" class="headerlink" title="Your Most Important Choices"></a>Your Most Important Choices</h3><p>To reach your goals faster, you need to change how you deal with these 5 types of choices:</p><ol><li><strong>Embracing pain that comes with pushing your limits.</strong> It is a fundamental law of nature that to evolve one has to push one’s limits in order to gain strength. <strong>Pain + Reflection = Progress</strong></li><li><strong>Accepting reality</strong>. People who know that understanding what is real is the first step toward optimally dealing with it make better decision.</li><li><strong>Worrying about reachings your goals rather than looking good.</strong> People who hide their weaknesses never learn how to properly deal with them and these weaknesses remain impediments in the future. </li><li><strong>Embracing first-order consequences, even when they are undesirable.</strong> People who overweigh the first-order consequences of their decisions and ignore the effects of second- and subsequent-order consequences rarely reach their goals.</li><li><strong>Taking ownership of your outcomes.</strong> Successful people understand that bad things come at everyone and that it is their responsibility to make their lives what they want them to be by successfully dealing with whatever challenges they face.</li></ol><blockquote><p>In summary, I believe that you can probably get what you want out of life if you can suspend your ego and take a no-excuse approach to achieving your goals with open-mindedness, determination, and courage, especially if you rely on the help of people who are strong in areas that you are weak.</p></blockquote><h3 id="You-Two-Yous-and-Your-Machine"><a href="#You-Two-Yous-and-Your-Machine" class="headerlink" title="You Two Yous and Your Machine"></a>You Two Yous and Your Machine</h3><blockquote><p>You do not rise to the level of your goals. You fall to the level of your systems.</p></blockquote><p>Think of yourself as a machine operating within a machine and know that you have the ability to alter your machines to produce better outcomes.</p><p><img src="principles-machine.webp"></p><p>To working on your machine, you need to seperate your two personalities:</p><ul><li>The <strong>Designer</strong>: the one who manages and plans the systems to achieve your goals</li><li>The <strong>doer</strong>: the one who works according to the plan created ny the Designer</li></ul><p>Your job as a Designer is to look at your resources and yourself as a Doer objectively to <strong>create the most efficient machine possible</strong>.</p><p>If you are not the best person for a job, fire yourself and find a good replacement.</p><h3 id="5-Step-Process-to-Get-What-You-Want-Out-of-Life"><a href="#5-Step-Process-to-Get-What-You-Want-Out-of-Life" class="headerlink" title="5-Step Process to Get What You Want Out of Life"></a>5-Step Process to Get What You Want Out of Life</h3><p>The process consists of five distinct steps:</p><ol><li><strong>Setting clear goals.</strong> To achieve your goals you have to prioritize, and that includes rejecting good alternatives. Avoid setting goals based on what you think you can achieve.</li><li><strong>Identifying and not tolerating problems.</strong> Most problems are potential improvements screaming at you. Don’t confuse problems with causes.</li><li><strong>Diagnosing the problem’s root cause.</strong> The most important qualities for successful diagnosing problems are logic, the ability to see multiple probabilities, and the willingness to touch people’s nerves to overcome the ego barriers that stand in the way of truth.</li><li><strong>Designing the plan and determining the solutions.</strong> Creating a design is like writing a movie script in that you visualize who will do what through time in order to achieve the goal.</li><li><strong>Doing the tasks set forward in the plan.</strong> It is critical to know each day what you need to do and have the discipline to be proactive.</li></ol><p>How often you take the cycle will dictate how fast you and your machine improves.</p><p><strong>Values -&gt; 1) Goals -&gt; 2) Problems -&gt; 3) Diagnoses -&gt; 4) Designs -&gt; 5) Tasks</strong></p><p><img src="principles-process.webp"></p><h3 id="Be-radically-Open-Minded"><a href="#Be-radically-Open-Minded" class="headerlink" title="Be radically Open Minded"></a>Be radically Open Minded</h3><p>Recognize your two barriers: <strong>your ego and your blind spots.</strong> Those who adapt do so by:</p><ol><li>Teaching their brains to work in a way that doesn’t come naturally like the creative designing an organization system.</li><li>Using compensating mechanisms like programmed reminders.</li><li>Relying on the help of others who are strong where they are weak.</li></ol><p><strong>Practice radical open-mindedness.</strong> Decision making is a two-step process: first take in all the relevant information, then decide. You’re looking for the best answer, not simply the best answer that you can come up with yourself.</p><p><strong>Appreciate the art of thoughtful disagreement.</strong> Open-mindedness isn’t easy because of your lizard brain, so you have to practice taking feedback impersonally.</p><h2 id="Management-Principles"><a href="#Management-Principles" class="headerlink" title="Management Principles"></a>Management Principles</h2><h3 id="Get-the-Culture-Right"><a href="#Get-the-Culture-Right" class="headerlink" title="Get the Culture Right"></a>Get the Culture Right</h3><blockquote><p>Make your passion and your work one and the same and do it with people you want to be with.</p></blockquote><ol><li><strong>Trust in Radical Truth and Radical Transparency.</strong> <ol><li>Realize that you have nothing to fear from knowing the truth.</li><li>Never say anything about someone that you wouldn’t say to them directly and don’t try people without accusing them to their faces.</li></ol></li><li><strong>Cultivate Meaningful Work and Meaningful Relationships</strong></li><li><strong>Create a Culture in Which It Is Okay to Make Mistakes and Unacceptable Not to Learn From Them.</strong><ol><li>Observe the patterns of mistakes to see if they are a product of weakness.</li><li>Get over “blame” and “credit” and get on with “accurate” and “inaccurate”.</li><li>Write down your weaknesses and the weaknesses of others to help remember and acknowledge them.</li><li>Be self-reflective and make sure your people are self-reflective</li><li>Teach and reinforce the merits of mistake-based learning.</li></ol></li><li><strong>Get and Stay in Syn.</strong><ol><li>Constantly get in synch about what is true and what to do about it.</li><li>Be assertive and open-minded at the same time.</li><li>Make sure responsible parties are open-minded about the questions and comments of others</li><li>Recognize that conflicts are essential for great relationships because they are the means by which people determine whether their principles are aligned and resolve their difference.</li><li>Dont’t treat all opinions as equally valuable.</li><li>Make sure people don’t confuse their right to complain, give advice, and debate with the right to make decisions.</li></ol></li></ol><h3 id="Get-the-Right-People"><a href="#Get-the-Right-People" class="headerlink" title="Get the Right People"></a>Get the Right People</h3><ol><li><strong>Recognize the Most Important Decisions You Make Are Who You Choose to Be Your Responsible Party.</strong><ol><li>Remember that almost everything good comes from having great people operating in a great culture.</li><li>The most important responsible parties are those who are most responsible for the goals, outcomes, and machines</li><li>Choose those who understand the difference between goals and tasks to run things</li></ol></li><li><strong>Recognize that People Are Built Very Differently.</strong><ol><li>Think about their very different values, abilities, and skills.</li><li>Recognize that the type of person you fit in the job must match the requirements for that job.</li><li>Understand that different ways of seeing things and think one way often have difficulty communicating and relating to people who see things and think another way.</li></ol></li><li><strong>Hire Right, Because the Penalties for Hiring Wrong are Huge.</strong><ol><li>Think though what values, abilities, and skills you are looking for.</li><li>Weigh values and abilities more heavily than skills in deciding whom to hire.</li><li>Write the profile of the person you are looking for into the job description.</li><li>Look for people who have lots of great questions.</li><li>Don’t hire people just to fit the first job they will do at your company; hire people you want to share your life with.</li><li>Pay for the person, not for the job.</li><li>Recognize there is a high probability that the person you hire will not be the great person you need for the job.</li></ol></li></ol><h3 id="Build-and-Evolve-Your-Machine"><a href="#Build-and-Evolve-Your-Machine" class="headerlink" title="Build and Evolve Your Machine"></a>Build and Evolve Your Machine</h3><ol><li><strong>Managing as Someone Operating a Machine to Achieve a Goal.</strong><ol><li>Understand the differences between managing, micromanaging, and not managing.</li><li>Constantly compare your outcomes to your goals.</li><li>Clearly assign responsibilities.</li><li>Hold people accountable and appreciate them holding you accountable.</li><li>Think like an owner, and expect the people you work with to do the same.</li><li>Force yourself and the people who work for you to do difficult things.</li><li>Communicate the plan clearly.</li><li>Learn confidence in your people - don’t presume it.</li><li>While logic drives our decisions, feelings are very relevant.</li><li>Escalate when you can’t adequately handle your responsibilities, and make sure that people who work for you do the same.</li></ol></li><li><strong>Probe Deep and Hard to Learn What to Expect from Your “Machine”.</strong><ol><li>Know what your people are like, and make sure they do their jobs excellently.</li><li>Constantly probe the people who report to you, and encourage them to probe you.</li><li>Probe to the level below the people who work for you.</li><li>Don’t “pick your battles.” Fight them all</li><li>Don’t let people off the hook</li><li>Don’t assume that people’s answers are correct</li><li>Make the probing transparent rather than private</li></ol></li><li><strong>Evaluate People Accurately, Not “Kindly”.</strong><ol><li>Evaluate employees with the same rigor as you evaluate job candidates</li><li>Know what makes your people tick, because people are your most important resource</li><li>Recognize that while most people prefer compliments over criticisms, there is nothing more valuable than accurate criticisms</li><li>Understand that you and the people you manage will go through a process of personal evolution</li><li>Help people through the pain that comes with exploring their weaknesses</li><li>Remember that you don’t need to get to the point of “beyond a shadow of a doubt” when judging people</li></ol></li><li><strong>Train and Test People Through Experiences.</strong><ol><li>Provide constant feedback to put the learning in perspective</li><li>Remember that everything is a case study</li><li>Know what types of mistakes are acceptable and unacceptable, and don’t allow the people who work for you to make the unacceptable ones</li><li>When you find that someone is not a good “click” for a job, get them out of it ASAP</li><li>Know that it is much worse to keep someone in a job who is not suited for it than it is to fire someone</li><li>Do not lower the bar</li></ol></li></ol><h3 id="Perceive-Diagnose-and-Solve-Problems"><a href="#Perceive-Diagnose-and-Solve-Problems" class="headerlink" title="Perceive, Diagnose, and Solve Problems"></a>Perceive, Diagnose, and Solve Problems</h3><ol><li><strong>Know How to Perceive Problems Effectively.</strong><ol><li>Have as many eyes looking for problems as possible</li><li>Don’t use the anonymous “we” and “they,” because that masks personal responsibility—use specific names</li><li>Be very specific about problems; don’t start with generalizations</li><li>Use the following tools to catch problems: issues logs, metrics, surveys, checklists, outside consultants, and internal auditors</li><li>The most common reason problems aren’t perceived is what I call the “frog in the boiling water” problem</li></ol></li><li><strong>Diagnose to Understand What the Problems Are Symptomatic Of.</strong><ol><li>Recognize that all problems are just manifestations of their root causes, so diagnose to understand what the problems are symptomatic of</li><li>Ask the following questions when diagnosing</li><li>To distinguish between a capacity issue and a capability issue, imagine how the person would perform at that particular function if they had ample capacity.</li><li>Keep in mind that diagnoses should produce outcomes</li></ol></li><li><strong>Design Your Machine to Achieve Your Goals.</strong><ol><li>Don’t act before thinking. Take the time to come up with a game plan</li><li>Recognize that design is an iterative process; between a bad “now” and a good “then” is a “working through it” period</li><li>Most importantly, build the organization around goals rather than tasks</li><li>Everyone must be overseen by a believable person who has high standards</li><li>Do not build the organization to fit the people</li><li>Have the clearest possible delineation of responsibilities and reporting lines</li><li>Assign responsibilities based on workflow design and people’s abilities, not job titles</li><li>Think clearly how things should go, and when they aren’t going that way, acknowledge it and investigate</li></ol></li><li><strong>Recognize the Power of Knowing How to Deal with Not Knowing.</strong><ol><li>Finding the path to success is at least as dependent on coming up with the right questions as coming up with answers.</li><li>Remember that your goal is to find the best answer, not to give the best one you have.</li></ol></li><li><strong>Remember the 80/20 Rule, and Know What the Key 20% Is.</strong><ol><li>Don’t mistake small things for unimportant things, because some small things can be very important</li><li>Make sure all the “must do’s” are above the bar before you do anything else</li><li>The best choices are the ones with more pros than cons, not those that don’t have any cons</li></ol></li></ol>]]></content>
    
    
    <categories>
      
      <category>Notes</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Coding</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>A Short Summary on Clean Code</title>
    <link href="/2021/10/12/clean-code/"/>
    <url>/2021/10/12/clean-code/</url>
    
    <content type="html"><![CDATA[<p>This blog post summarizes the guidelines and best practices for writing high-quality code from the book Clean Code by Robert C. Martin. Download the PDF version of the book <a href="clean-code.pdf" download>here</a>.</p><span id="more"></span><h2 id="Meaningful-Names"><a href="#Meaningful-Names" class="headerlink" title="Meaningful Names"></a>Meaningful Names</h2><h3 id="Use-Intention-Reveraling-Names"><a href="#Use-Intention-Reveraling-Names" class="headerlink" title="Use Intention-Reveraling Names"></a>Use Intention-Reveraling Names</h3><p>The name of a variable, function, or class, should tell you why it exists, what it does, and how it is used. If a name requires a comment, then the name does not reveal its intent.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">int</span> d; <span class="hljs-comment">// elapsed time in days</span><br><span class="hljs-keyword">int</span> elapsedTimeInDays;<br></code></pre></td></tr></table></figure><p><strong>Implicity</strong> of the code: the degree to which the context is not explicit in the code itself.</p><h3 id="Avoid-Disinformation"><a href="#Avoid-Disinformation" class="headerlink" title="Avoid Disinformation"></a>Avoid Disinformation</h3><p>We should avoid words whose entrenched meanings vary from our intended meaning.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">int</span> hp, aix, sco;<br><span class="hljs-keyword">int</span> l, O; <span class="hljs-comment">// looks like the constants 1 and 0, respectively</span><br></code></pre></td></tr></table></figure><p>Spelling similar concepts similarly is <strong>information</strong>. Using inconsistent spellings is <strong>disinformation</strong>.</p><h3 id="Make-Meaningful-Distinctions"><a href="#Make-Meaningful-Distinctions" class="headerlink" title="Make Meaningful Distinctions"></a>Make Meaningful Distinctions</h3><p>Number-series naming is noninformative.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs java">string date1, date2;<br></code></pre></td></tr></table></figure><p>Noise words are redundant and another meaningless distinction.</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs javascript"><span class="hljs-keyword">let</span> product, productObject, productData, productInfo;<br></code></pre></td></tr></table></figure><h3 id="Use-Pronounceable-Names"><a href="#Use-Pronounceable-Names" class="headerlink" title="Use Pronounceable Names"></a>Use Pronounceable Names</h3><p>Programming is a social activity. Make names pronounceable so that intelligent conversations are possible.</p><h3 id="Use-Searchable-Names"><a href="#Use-Searchable-Names" class="headerlink" title="Use Searchable Names"></a>Use Searchable Names</h3><p>Single-letter names and numeric constants are not easy to locate across a body of text. In this regard, longer names trump shorter names, and any searchable name trumps a constant in code.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">int</span> realDaysPerIdealDay = <span class="hljs-number">4</span>;<br><span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> WORK_DAYS_PER_WEEK = <span class="hljs-number">5</span>;<br></code></pre></td></tr></table></figure><p>The length of a name should correspond to the size of its scope.</p><h3 id="Avoid-Encodings"><a href="#Avoid-Encodings" class="headerlink" title="Avoid Encodings"></a>Avoid Encodings</h3><p>Encoding type or scope information into names simply adds an extra burden of deciphering.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs java">string strFirstName;<br><span class="hljs-keyword">int</span> nUsers;<br></code></pre></td></tr></table></figure><h3 id="Avoid-Mental-Mapping"><a href="#Avoid-Mental-Mapping" class="headerlink" title="Avoid Mental Mapping"></a>Avoid Mental Mapping</h3><p>Single-letter names for loop counters are traditional, but in most other context a single-letter name is a poor choice.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">int</span> i, j, k;<br></code></pre></td></tr></table></figure><p>Professional programmers understand that <strong>clarity</strong> is king.</p><h3 id="Class-Names"><a href="#Class-Names" class="headerlink" title="Class Names"></a>Class Names</h3><p>Classes and objects should have noun or noun phrase names. A class name should not be a verb.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs java">Customer, WikiPage, Account, AddressParser;<br></code></pre></td></tr></table></figure><h3 id="Method-Names"><a href="#Method-Names" class="headerlink" title="Method Names"></a>Method Names</h3><p>Methods should have verb or verb phrase names. Accessors, mutators, and predicates should be named for their value and prefixed with <code>get</code>, <code>set</code>, and <code>is</code>.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs java">string name = employee.getName();<br>customer.setName(<span class="hljs-string">&quot;mike&quot;</span>);<br><span class="hljs-keyword">if</span> (paycheck.isPosted())...<br></code></pre></td></tr></table></figure><h3 id="Avoid-Ambiguity"><a href="#Avoid-Ambiguity" class="headerlink" title="Avoid Ambiguity"></a>Avoid Ambiguity</h3><p>Pick one word for one abstract concept and stick with it. A consistent lexicon is a great boon.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs java">Controller, Manager, Driver;<br></code></pre></td></tr></table></figure><p>Avoid using the same word for two purposes with different <strong>semantics</strong>. </p><h3 id="Solution-and-Problem-Domain-Names"><a href="#Solution-and-Problem-Domain-Names" class="headerlink" title="Solution and Problem Domain Names"></a>Solution and Problem Domain Names</h3><p>Use the name from the solution domain such as computer science terms, algorithm names, patter names, math terms, and so forth.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs java">AccountVisitor, JobQueue;<br></code></pre></td></tr></table></figure><p>Seperate solution and problem domain concepts.</p><h3 id="Add-Meaningful-Context"><a href="#Add-Meaningful-Context" class="headerlink" title="Add Meaningful Context"></a>Add Meaningful Context</h3><p>Place names in context by enclosing them in well-named classes, functions, or namespaces.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs java">string firstName, lastName, addrState, addrCity;<br></code></pre></td></tr></table></figure><p>Shorter names are generally better than longer ones, so long as they are clear. Add no more context to a name than is necessary.</p><h2 id="Function"><a href="#Function" class="headerlink" title="Function"></a>Function</h2><h3 id="Keep-Functions-Small"><a href="#Keep-Functions-Small" class="headerlink" title="Keep Functions Small"></a>Keep Functions Small</h3><p>The whole function must fit into the screen and not too wide so that it’s easy to read without scrolling. Every function should be around four lines long.</p><p>This implies that the blocks within <code>if</code>, <code>else</code>, <code>while</code> statements should be a function call which also adds documentary value.</p><p>The indent level of a function should not be greater than one or two.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> String <span class="hljs-title">renderPageWithSetupsAndTeardowns</span> <span class="hljs-params">(</span></span><br><span class="hljs-params"><span class="hljs-function">    PageData pageData, <span class="hljs-keyword">boolean</span> isSuite)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>    <span class="hljs-keyword">if</span> (isTestPage(pageData))<br>        includeSetupAndTeardownPages(pageData, isSuite);<br>    <span class="hljs-keyword">return</span> pageData.getHtml();<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="Do-One-Thing"><a href="#Do-One-Thing" class="headerlink" title="Do One Thing"></a>Do One Thing</h3><blockquote><p>Functions should do one thing. They should do it well. They should do it only.</p></blockquote><p>The reason we write functions is to decompose a larger concept into a set of steps at the next level of abstraction.</p><p>A function is doing more than one thing if we can extract another function from it with a name that is not merely a restatement of its implementation.</p><h3 id="One-Level-of-Abstraction-per-Function"><a href="#One-Level-of-Abstraction-per-Function" class="headerlink" title="One Level of Abstraction per Function"></a>One Level of Abstraction per Function</h3><p>Mixing levels of abstraction within a function is always confusing.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs java">pageData.getHtml(); <span class="hljs-comment">// high level</span><br>String pagePathName = PathParser.render(pagePath); <span class="hljs-comment">// intermediate level</span><br>buffer.append(<span class="hljs-string">&quot;\n&quot;</span>); <span class="hljs-comment">// low level</span><br></code></pre></td></tr></table></figure><p><em>The Stepdown Rule</em>: Every function should be followed by those at the next level of abstraction so that we can read the program as though it were a set of paragraphs.</p><h3 id="Avoid-Switch-Statements"><a href="#Avoid-Switch-Statements" class="headerlink" title="Avoid Switch Statements"></a>Avoid Switch Statements</h3><p>Use polymorphism and bury the switch statement in the basement of an abstract factory.</p><h3 id="Use-Descriptive-Names"><a href="#Use-Descriptive-Names" class="headerlink" title="Use Descriptive Names"></a>Use Descriptive Names</h3><p>A long descriptive name is better than a short enigmatic name.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs java">includeTeardownPages();<br>includeSuiteTeardownPage();<br></code></pre></td></tr></table></figure><p>Try serveral different names and read the code with each in place. Be consistent in your names.</p><h3 id="Function-Arguments"><a href="#Function-Arguments" class="headerlink" title="Function Arguments"></a>Function Arguments</h3><p>The ideal number of arguments for a function is zero (niladic). Next comes one (monadic), followed closely by two (dyadic). Three arguments (triadic) should be avoided where possible.</p><h4 id="Common-Monadic-Forms"><a href="#Common-Monadic-Forms" class="headerlink" title="Common Monadic Forms"></a>Common Monadic Forms</h4><p>There are three reasons to pass a single argument into a function.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">// asking a question about the argument</span><br><span class="hljs-function"><span class="hljs-keyword">boolean</span> <span class="hljs-title">fileExists</span><span class="hljs-params">(<span class="hljs-string">&quot;MyFile&quot;</span>)</span></span>;<br><span class="hljs-comment">// operating on the argument, transforming it, and returning it</span><br><span class="hljs-function">InputStream <span class="hljs-title">fileOpen</span><span class="hljs-params">(<span class="hljs-string">&quot;MyFile&quot;</span>)</span></span>;<br><span class="hljs-comment">// using the argument to alter the state of the system (an event)</span><br><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">passwordAttemptFailedNtimes</span><span class="hljs-params">(<span class="hljs-keyword">int</span> attempts)</span></span><br></code></pre></td></tr></table></figure><h4 id="Flag-Arguments"><a href="#Flag-Arguments" class="headerlink" title="Flag Arguments"></a>Flag Arguments</h4><p>Passing a boolean into a function is a terrible practice.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs java">render(<span class="hljs-keyword">boolean</span> isSuite);<br><span class="hljs-comment">// split the function into two</span><br>renderForSuite();<br>renderForSingleTest();<br></code></pre></td></tr></table></figure><h4 id="Dyadic-Functions"><a href="#Dyadic-Functions" class="headerlink" title="Dyadic Functions"></a>Dyadic Functions</h4><p>A function with two arguments is harder to understand than a monadic function.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs java">Point p = <span class="hljs-keyword">new</span> Point(<span class="hljs-number">0</span>, <span class="hljs-number">0</span>);<br>assertEquals(expected, actual);<br></code></pre></td></tr></table></figure><h4 id="Triads"><a href="#Triads" class="headerlink" title="Triads"></a>Triads</h4><p>For triads, the issues of ordering, pausing, and ignoring are more than doubled.</p><h4 id="Argument-Objects"><a href="#Argument-Objects" class="headerlink" title="Argument Objects"></a>Argument Objects</h4><p>Arguments can be wrapped into a class of their own.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-function">Circle <span class="hljs-title">makeCircle</span><span class="hljs-params">(Point center, <span class="hljs-keyword">double</span> radius)</span></span>;<br></code></pre></td></tr></table></figure><h4 id="Argument-Lists"><a href="#Argument-Lists" class="headerlink" title="Argument Lists"></a>Argument Lists</h4><p>Sometimes we want to pass a variable number of arguments into a function.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">public</span> String <span class="hljs-title">format</span><span class="hljs-params">(String format, Object... args)</span></span><br></code></pre></td></tr></table></figure><h4 id="Verbs-and-Keywords"><a href="#Verbs-and-Keywords" class="headerlink" title="Verbs and Keywords"></a>Verbs and Keywords</h4><p>Function names can explain the intent of the function and the order and intent of the arguments. </p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs java">writeField(name);<br>assertExpectedEqualsActual(expected, actual);<br></code></pre></td></tr></table></figure><h3 id="Avoid-Side-Effects"><a href="#Avoid-Side-Effects" class="headerlink" title="Avoid Side Effects"></a>Avoid Side Effects</h3><p>Functions can make unexpected changes to variables of its own class, parameters passed into the function or system globals. This can result in strange temporal couplings and order dependencies.</p><p>Arguments are most naturally interpreted as inputs to a function. Anything that forces you to check the function signature is a cognitive break and should be avoided.</p><h3 id="Command-Query-Seperation"><a href="#Command-Query-Seperation" class="headerlink" title="Command Query Seperation"></a>Command Query Seperation</h3><p>Functions should either do something or answer something, but not both.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">if</span> (set(<span class="hljs-string">&quot;username&quot;</span>, <span class="hljs-string">&quot;unclebob&quot;</span>))...<br><span class="hljs-comment">// seperate the command from the query</span><br><span class="hljs-keyword">if</span> (attributeExists(<span class="hljs-string">&quot;username&quot;</span>)) &#123;<br>    setAttribute(<span class="hljs-string">&quot;username&quot;</span>, <span class="hljs-string">&quot;unclebob&quot;</span>);<br>    ...<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="Prefer-Exceptions-to-Returning-Error-Codes"><a href="#Prefer-Exceptions-to-Returning-Error-Codes" class="headerlink" title="Prefer Exceptions to Returning Error Codes"></a>Prefer Exceptions to Returning Error Codes</h3><p>Returning error codes from command functions violates command query seperation, leading to deeply nested structures.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">if</span> (deletePage(page) == E_OK)...<br><span class="hljs-comment">// use exceptions instead of returned error codes</span><br><span class="hljs-keyword">try</span> &#123;<br>    deletePage(page);<br>&#125;<br><span class="hljs-keyword">catch</span> (Exception e) &#123;<br>    logger.log(e.getMessage());<br>&#125;<br></code></pre></td></tr></table></figure><p>It is better to extract the bodies of the <code>try</code> and <code>catch</code> blocks out into functions of their own. A function that handles errors should do nothing else.</p><h3 id="Avoid-Repetition"><a href="#Avoid-Repetition" class="headerlink" title="Avoid Repetition"></a>Avoid Repetition</h3><p>Duplication is a problem because it bloats the code, requires manifold modification for a change of algorithm and magnifies opportunity for an error of omission.</p><h3 id="Structured-Programming"><a href="#Structured-Programming" class="headerlink" title="Structured Programming"></a>Structured Programming</h3><blockquote><p>Every function, and every block within a function, should have one entry and one exit.</p></blockquote><p>There should only be one <code>return</code> statement in a function, no <code>break</code> or <code>continue</code> statements in a loop, and never any <code>goto</code> statements. It is only in larger functions that such rules provide significant benefit.</p><h2 id="Comments"><a href="#Comments" class="headerlink" title="Comments"></a>Comments</h2><p>The proper use of comments is to compensate for our failure to express ourself in code. Programmers cannot realistically maintain comments.</p><p>Inaccurate comments are far worse than no comments at all.</p><h3 id="Comments-Do-Not-Make-Up-for-Bad-Code"><a href="#Comments-Do-Not-Make-Up-for-Bad-Code" class="headerlink" title="Comments Do Not Make Up for Bad Code"></a>Comments Do Not Make Up for Bad Code</h3><p>Clear and expressive code with few comments is far superior to cluttered and complex code with lots of comments.</p><h3 id="Explain-Yourself-in-Code"><a href="#Explain-Yourself-in-Code" class="headerlink" title="Explain Yourself in Code"></a>Explain Yourself in Code</h3><p>There are times when code makes a poor vehicle for explanation. In many cases it’s simple to create a function that says the same thing as the comment you want to write.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">// Check to see if the employee is eligible for full benefits</span><br><span class="hljs-keyword">if</span> ((employee.flags &amp; HOURLY_FLAG) &amp;&amp;<br>    (employee.age &gt; <span class="hljs-number">65</span>))<br><br><span class="hljs-keyword">if</span> (employee.isEligibleForFullBenefits())<br></code></pre></td></tr></table></figure><h3 id="Good-Comments"><a href="#Good-Comments" class="headerlink" title="Good Comments"></a>Good Comments</h3><p>Some comments are necessary or beneficial.</p><h4 id="Legal-Comments"><a href="#Legal-Comments" class="headerlink" title="Legal Comments"></a>Legal Comments</h4><p>Copyright and authorship statements are necessary and reasonable things to put into a comment at the start of each source file.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">// Copyright (C) 2003,2004,2005 by Object Mentor, Inc. All rights reserved.</span><br><span class="hljs-comment">// Released under the terms of the GNU General Public License version 2 or later.</span><br></code></pre></td></tr></table></figure><h4 id="Informative-Comments"><a href="#Informative-Comments" class="headerlink" title="Informative Comments"></a>Informative Comments</h4><p>It is sometimes useful to provide basic information with a comment.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">// format matched kk:mm:ss EEE, MMM dd, yyyy</span><br>Pattern timeMatcher = Pattern.compile(<br>    *\\d*:\\d*:\\d* \\w*, \\w* \\d*, \\d**);<br></code></pre></td></tr></table></figure><h4 id="Explanation-of-Intent"><a href="#Explanation-of-Intent" class="headerlink" title="Explanation of Intent"></a>Explanation of Intent</h4><p>Sometimes a comment provides the intent behind a decision.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">// This is our best attempt to get a race condition</span><br><span class="hljs-comment">// by creating large number of threads.</span><br><span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">25000</span>; i++) &#123;<br>    WidgetBuilderThread widgetBuilderThread = <br>        <span class="hljs-keyword">new</span> WidgetBuilderThread(widgetBuilder, text, parent, failFlag);<br>    Thread thread = <span class="hljs-keyword">new</span> Thread(widgetBuilderThread);<br>    thread.start();<br>&#125;<br></code></pre></td></tr></table></figure><h4 id="Clarification"><a href="#Clarification" class="headerlink" title="Clarification"></a>Clarification</h4><p>Sometimes it is helpful to translate the meaning of some obscure argument or return value into something that’s readable.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs java">assertTrue(a.compareTo(a) == <span class="hljs-number">0</span>); <span class="hljs-comment">// a == a</span><br>assertTrue(a.compareTo(b) == -<span class="hljs-number">1</span>); <span class="hljs-comment">// a &lt; b</span><br></code></pre></td></tr></table></figure><p>There is a substantial risk that a clarifying comment is incorrect and it is diffcult to verify.</p><h4 id="Warning-of-Consequences"><a href="#Warning-of-Consequences" class="headerlink" title="Warning of Consequences"></a>Warning of Consequences</h4><p>Sometimes it is useful to warn other programmers about certain consequences.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">// SimpleDateFormat is not thread safe,</span><br><span class="hljs-comment">// so we need to create each instance independently.</span><br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> SimpleDateFormat <span class="hljs-title">makeStandardHttpDateFormat</span><span class="hljs-params">()</span>...</span><br></code></pre></td></tr></table></figure><h4 id="TODO-Comments"><a href="#TODO-Comments" class="headerlink" title="TODO Comments"></a>TODO Comments</h4><p>It is sometimes reasonable to leave “To do” notes in the form of <code>TODO</code> comments.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">// TODO-MdM these are not needed</span><br><span class="hljs-comment">// We expect this to go away when we do the checkout model</span><br><span class="hljs-function"><span class="hljs-keyword">protected</span> VersionInfo <span class="hljs-title">makeVersion</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span> Exception</span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-keyword">return</span> <span class="hljs-keyword">null</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p><code>TODO</code>s are jobs that the programmer thinks should be done, not an excuse to leave bad code in the system.</p><h4 id="Amplification"><a href="#Amplification" class="headerlink" title="Amplification"></a>Amplification</h4><p>A comment may be used to Amplify the importance of something that may otherwise seem inconsequential.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs java">String listItemContent = match.group(<span class="hljs-number">3</span>).trim();<br><span class="hljs-comment">// the trim is real important. It removes the starting</span><br><span class="hljs-comment">// spaces that could cause the item to be recognized</span><br><span class="hljs-comment">// as another list.</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Notes</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Programming</tag>
      
      <tag>Coding</tag>
      
      <tag>Java</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Granger Causality and Hypothesis Testing</title>
    <link href="/2021/07/19/time-series/"/>
    <url>/2021/07/19/time-series/</url>
    
    <content type="html"><![CDATA[<p>This is the reading notes on Introduction to Modern Time Series Analysis by by G. Kirchgässner and Jürgen Wolters. This is done as a preparatory work for the project on detecting causal structure in time series in Part IIB of the Engineering Tripos at the University of Cambridge.</p><span id="more"></span><h2 id="Linear-Models"><a href="#Linear-Models" class="headerlink" title="Linear Models"></a>Linear Models</h2><h3 id="Simple-linear-regression"><a href="#Simple-linear-regression" class="headerlink" title="Simple linear regression"></a>Simple linear regression</h3><p>If we have a simple linear regression model<br>$$y_i= a + bx_i+ ε_i$$<br>then we can reparameterise it to<br>$$y_i= a^\prime + b(x_i− \bar{x}) + ε_i$$<br>where $\bar{x}=\sum x_i/n$ and $a^\prime = a + b \bar{x}$.</p><p>In matrix form,<br>$$X = \begin{pmatrix}<br>1 &amp; (x_1 - \bar{x}) \\<br>\vdots &amp; \vdots \\<br>1 &amp; (x_n - \bar{x})<br>\end{pmatrix}$$</p><p>Since $\sum (x_i− \bar{x}) = 0$, in $X^T X$, the off-diagonals are all $0$, and we have<br>$$X^T X = \begin{pmatrix}<br>n &amp; 0 \\<br>0 &amp; S_{xx}<br>\end{pmatrix}$$<br>where $S_{xx} = \sum (x_i - \bar{x})^2$.</p><p>So<br>$$\hat{\beta} = (X^T X)^{-1} X^T Y = \begin{pmatrix}<br>\bar{y} \\<br>\frac{S_{xy}}{S_{xx}}<br>\end{pmatrix}$$<br>where $S_{xy} = \sum y_i (x_i - \bar{x})$.</p><p>Hence the estimated intercept is $\hat{a}^\prime= \bar{y}$, and the estimated gradient is<br>$$\begin{aligned}<br>\hat{b} &amp;=\frac{S_{x y}}{S_{x x}} \\<br>&amp;=\frac{\sum_{i} y_{i}\left(x_{i}-\bar{x}\right)}{\sum_{i}\left(x_{i}-\bar{x}\right)^{2}} \\<br>&amp;=\frac{\sum_{i}\left(y_{i}-\bar{y}\right)\left(x_{i}-\bar{x}\right)}{\sqrt{\sum_{i}\left(x_{i}-\bar{x}\right)^{2} \sum_{i}\left(y_{i}-\bar{y}\right)^{2}}} \times \sqrt{\frac{S_{y y}}{S_{x x}}} \\<br>&amp;=r \times \sqrt{\frac{S_{y y}}{S_{x x}}}<br>\end{aligned}<br>$$</p><p>So the gradient is the <em>Pearson product-moment correlation coefficient</em> $r$ times the ratio of the empirical standard deviations of the $y$’s and $x$’s.</p><p>Hence we get $\operatorname{cov}(\hat{\boldsymbol{\beta}})=\left(X^{T} X\right)^{-1} \sigma^{2}$, and so from our expression of $\left(X^{T} X\right)^{-1}$,<br>$$<br>\operatorname{var}\left(\hat{a}^{\prime}\right)=\operatorname{var}(\bar{y})=\frac{\sigma^{2}}{n}, \quad \operatorname{var}(\hat{b})=\frac{\sigma^{2}}{S_{x x}}<br>$$<br>The <em>residual sum of squares</em> is<br>$$\operatorname{RSS}=(Y-X \hat{\boldsymbol{\beta}})^{T}(Y-X \hat{\boldsymbol{\beta}}) \sim \sigma^{2} \chi_{n-p}^{2}$$</p><h3 id="Inference-for-boldsymbol-beta"><a href="#Inference-for-boldsymbol-beta" class="headerlink" title="Inference for $\boldsymbol{\beta}$"></a>Inference for $\boldsymbol{\beta}$</h3><p>We know that $\hat{\boldsymbol{\beta}} \sim N_{p}\left(\boldsymbol{\beta}, \sigma^{2}\left(X^{T} X\right)^{-1}\right)$. So<br>$$<br>\hat{\beta}_{j} \sim N\left(\beta_{j}, \sigma^{2}\left(X^{T} X\right)_{j j}^{-1}\right)<br>$$<br>The standard error of $\hat{\beta}_{j}$ is defined to be<br>$$<br>\operatorname{SE}\left(\hat{\beta}_{j}\right)=\sqrt{\tilde{\sigma}^{2}\left(X^{T} X\right)_{j j}^{-1}}<br>$$<br>where $\tilde{\sigma}^{2}=\operatorname{RSS} /(n-p)$ is an unbiased estimator of $\sigma^{2}$. $\tilde{\sigma}$ is often known as the residual standard error on $n-p$ degrees of freedom.</p><p>Then<br>$$<br>\frac{\hat{\beta}_{j}-\beta_{j}}{\operatorname{SE}\left(\hat{\beta}_{j}\right)} \sim t_{n-p}<br>$$<br>So a $100(1-\alpha) %$ confidence interval for $\beta_{j}$ has end points $\hat{\beta}_{j} \pm \operatorname{SE}\left(\hat{\beta}_{j}\right) t_{n-p}\left(\frac{\alpha}{2}\right)$.</p><p>In particular, if we want to test $H_{0}: \beta_{j}=0$, we use the fact that under $H_{0}$, $\frac{\hat{\beta}_{j}}{\operatorname{SE}\left(\hat{\beta}_{j}\right)} \sim t_{n-p} .$</p><h2 id="Hypothesis-Testing"><a href="#Hypothesis-Testing" class="headerlink" title="Hypothesis Testing"></a>Hypothesis Testing</h2><h3 id="Hypothesis-testing-in-general-linear-models"><a href="#Hypothesis-testing-in-general-linear-models" class="headerlink" title="Hypothesis testing in general linear models"></a>Hypothesis testing in general linear models</h3><p>Suppose $\underset{n \times p}{X}=\left(\underset{n \times p_{0}}{X_{0}} \underset{n \times\left(p-p_{0}\right)}{X_{1}}\right)$ and $\mathbf{B}=\left(\begin{array}{c}\boldsymbol{\beta}_{0} \\ \boldsymbol{\beta}_{1}\end{array}\right)$, where $\operatorname{rank}(X)=$<br>$p, \operatorname{rank}\left(X_{0}\right)=p_{0}$<br>We want to test $H_{0}: \boldsymbol{\beta}_{1}=0$ against $H_{1}: \boldsymbol{\beta}_{1} \neq 0$. Under $H_{0}, X_{1} \boldsymbol{\beta}_{1}$ vanishes<br>and<br>$$<br>\mathbf{Y}=X_{0} \boldsymbol{\beta}+\varepsilon<br>$$<br>Under $H_{0}$, the mle of $\boldsymbol{\beta}_{0}$ and $\sigma^{2}$ are<br>$$<br>\begin{aligned}<br>&amp;\hat{\hat{\boldsymbol{\beta}}}_{0}=\left(X_{0}^{T} X_{0}\right)^{-1} X_{0}^{T} \mathbf{Y} \\<br>&amp;\hat{\hat{\sigma}}^{2}=\frac{\mathrm{RSS}_{0}}{n}=\frac{1}{n}\left(\mathbf{Y}-X_{0} \hat{\boldsymbol{\beta}}_{0}\right)^{T}\left(\mathbf{Y}-X_{0} \hat{\boldsymbol{\beta}}_{0}\right)<br>\end{aligned}<br>$$<br>and we have previously shown these are independent.</p><p>So the fitted values under $H_{0}$ are<br>$$<br>\hat{\hat{\mathbf{Y}}}=X_{0}\left(X_{0}^{T} X_{0}\right)^{-1} X_{0}^{T} \mathbf{Y}=P_{0} \mathbf{Y}<br>$$<br>where $P_{0}=X_{0}\left(X_{0}^{T} X_{0}\right)^{-1} X_{0}^{T}$.</p><p>The generalized likelihood ratio test of $H_{0}$ against $H_{1}$ is<br>$$<br>\begin{aligned}<br>\Lambda_{\mathbf{Y}}\left(H_{0}, H_{1}\right) &amp;=\frac{\left(\frac{1}{\sqrt{2 \pi \hat{\sigma}^{2}}}\right) \exp \left(-\frac{1}{2 \hat{\sigma}^{2}}(\mathbf{Y}-X \hat{\boldsymbol{\beta}})^{T}(\mathbf{Y}-X \hat{\boldsymbol{\beta}})\right)}{\left(\frac{1}{\sqrt{2 \pi \hat{\sigma}^{2}}}\right) \exp \left(-\frac{1}{\hat{\hat{\sigma}}^{2}}\left(\mathbf{Y}-X \hat{\boldsymbol{\beta}}_{0}\right)^{T}\left(\mathbf{Y}-X \hat{\boldsymbol{\beta}}_{0}\right)\right)} \\<br>&amp;=\left(\frac{\hat{\hat{\sigma}}^{2}}{\hat{\sigma}^{2}}\right)^{n / 2} \\<br>&amp;=\left(\frac{\operatorname{RSS}_{0}}{\operatorname{RSS}}\right)^{n / 2} \\<br>&amp;=\left(1+\frac{\mathrm{RSS}_{0}-\mathrm{RSS}}{\mathrm{RSS}}\right)^{n / 2}<br>\end{aligned}<br>$$<br>We reject $H_{0}$ when $2 \log \Lambda$ is large, equivalently when $\frac{\mathrm{RSS}_{0}-\mathrm{RSS}}{\mathrm{RSS}}$ is large. Under $H_{0}$, we have<br>$$<br>2 \log \Lambda=n \log \left(1+\frac{\mathrm{RSS}_{0}-\mathrm{RSS}}{\mathrm{RSS}}\right)<br>$$<br>which is approximately a $\chi_{p-p_{0}}^{2}$ random variable.</p><p>So under $H_{0}$,<br>$$<br>F=\frac{\mathbf{Y}^{T}\left(P-P_{0}\right) \mathbf{Y} /\left(p-p_{0}\right)}{\mathbf{Y}^{T}\left(I_{n}-P\right) \mathbf{Y} /(n-p)}=\frac{\left(\mathrm{RSS}_{0}-\operatorname{RSS}\right) /\left(p-p_{0}\right)}{\operatorname{RSS} /(n-p)} \sim F_{p-p_{0}, n-p}<br>$$<br>Hence we reject $H_{0}$ if $F&gt;F_{p-p_{0}, n-p}(\alpha)$. $\mathrm{RSS}_{0}-\mathrm{RSS}$ is the reduction in the sum of squares due to fitting $\boldsymbol{\beta}_{1}$ in addition to $\boldsymbol{\beta}_{0}$.</p><h2 id="Granger-Causality"><a href="#Granger-Causality" class="headerlink" title="Granger Causality"></a>Granger Causality</h2><h3 id="The-Direct-Granger-Procedure"><a href="#The-Direct-Granger-Procedure" class="headerlink" title="The Direct Granger Procedure"></a>The Direct Granger Procedure</h3><p>To test for simple causality from x to y, it is examined whether the lagged values of x in the regression of y on lagged values of x and y significantly reduce the error variance. By using OLS, the following equation is estimated:<br>$$<br>y_{t}=\alpha_{0}+\sum_{k=1}^{k_{1}} \alpha_{11}^{k} y_{t-k}+\sum_{k=k_{0}}^{k_{2}} \alpha_{12}^{k} x_{t-k}+u_{1, t}<br>$$<br>with $k_0 = 1$. An F test is applied to test the null hypothesis, $H_0: \alpha^{1}_{12} = \alpha^{1}_{12} = \cdots = \alpha^{k_2}_{12} = 0$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">causality_tests</span>(<span class="hljs-params">y, x, alpha=<span class="hljs-number">0.05</span>, k_1=<span class="hljs-number">1</span>, maxlag=<span class="hljs-number">1</span>, verbose=<span class="hljs-literal">False</span></span>):</span><br>    <span class="hljs-keyword">for</span> k_2 <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, maxlag+<span class="hljs-number">1</span>):<br>        p = <span class="hljs-number">1</span> + k_1 + k_2<br>        n = y.shape[<span class="hljs-number">0</span>] - np.<span class="hljs-built_in">max</span>([k_1, k_2])<br>        <br>        _,_,RSS = fit_xy(y, x, k_1, k_2)<br>        _,_,RSS_0 = fit(y, k_1)<br>        <br>        chi2 = n * np.log(RSS_0 / RSS)<br>        f = ((RSS_0 - RSS) / k_2) / (RSS / (n-p))<br></code></pre></td></tr></table></figure><p><img src="fit.png"></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs routeros">Hypothesis Test (<span class="hljs-attribute">p</span>=1)<br>F test:       <span class="hljs-attribute">F</span>=24.4610 , <span class="hljs-attribute">p</span>=0.0000, <span class="hljs-attribute">df_denom</span>=199, <span class="hljs-attribute">df_num</span>=1<br>chi2 test: <span class="hljs-attribute">chi2</span>=23.3023 , <span class="hljs-attribute">p</span>=0.0000, <span class="hljs-attribute">df</span>=1<br>Reject <span class="hljs-literal">null</span> hypothesis<br><br>Hypothesis Test (<span class="hljs-attribute">p</span>=2)<br>F test:       <span class="hljs-attribute">F</span>=8.2501  , <span class="hljs-attribute">p</span>=0.0045, <span class="hljs-attribute">df_denom</span>=197, <span class="hljs-attribute">df_num</span>=1<br>chi2 test: <span class="hljs-attribute">chi2</span>=8.2051  , <span class="hljs-attribute">p</span>=0.0042, <span class="hljs-attribute">df</span>=1<br>Reject <span class="hljs-literal">null</span> hypothesis<br><br>Hypothesis Test (<span class="hljs-attribute">p</span>=3)<br>F test:       <span class="hljs-attribute">F</span>=0.4181  , <span class="hljs-attribute">p</span>=0.5187, <span class="hljs-attribute">df_denom</span>=195, <span class="hljs-attribute">df_num</span>=1<br>chi2 test: <span class="hljs-attribute">chi2</span>=0.4262  , <span class="hljs-attribute">p</span>=0.5139, <span class="hljs-attribute">df</span>=1<br>Accept <span class="hljs-literal">null</span> hypothesis<br><br>Hypothesis Test (<span class="hljs-attribute">p</span>=4)<br>F test:       <span class="hljs-attribute">F</span>=4.9506  , <span class="hljs-attribute">p</span>=0.0272, <span class="hljs-attribute">df_denom</span>=193, <span class="hljs-attribute">df_num</span>=1<br>chi2 test: <span class="hljs-attribute">chi2</span>=5.0148  , <span class="hljs-attribute">p</span>=0.0251, <span class="hljs-attribute">df</span>=1<br>Reject <span class="hljs-literal">null</span> hypothesis<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Notes</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Cambridge</tag>
      
      <tag>Engineering</tag>
      
      <tag>Information</tag>
      
      <tag>Time series</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Black Scholes Model with Stock Simulation</title>
    <link href="/2021/07/17/black-scholes/"/>
    <url>/2021/07/17/black-scholes/</url>
    
    <content type="html"><![CDATA[<p>The article explores the use of geometric Brownian Motion (GBM) to simulate the price of stocks. The concept naturally extends to the Black-Scholes-Merton (BSM) model which is widely used to estimate the pricing variation of financial instruments such as an options contract. Monte Carlo simulation (MCS) is then used to estimate the stock pricing and validate the model predictions.</p><span id="more"></span><h2 id="Geometric-Brownian-Motion"><a href="#Geometric-Brownian-Motion" class="headerlink" title="Geometric Brownian Motion"></a>Geometric Brownian Motion</h2><h3 id="Stochastic-process"><a href="#Stochastic-process" class="headerlink" title="Stochastic process"></a>Stochastic process</h3><p>A geometric Brownian motion (GBM) is a continuous-time stochastic process in which the logarithm of the randomly varying quantity follows a Brownian motion (also called a Wiener process) with drift. The stock price $S_t$ is said to follow a GBM if it satisfies the following stochastic differential equation (SDE):</p><p>$$dS_t = \mu S_t dt + \sigma S_t dW_t$$</p><p>$W_t$ is a Wiener process or Brownian motion, and the expected return $\mu$ and the standard deviation of returns (volatility) $\sigma$ are constants. Note that $W_t$ is normally distributed with mean $0$ and variance $t$. For an arbitrary initial value $S_0$ the above SDE has the analytic solution:</p><p>$$S_t = S_0 \exp \left[ \left( \mu - \frac{\sigma^2}{2} \right) t + \sigma W_t \right] = \exp \left[ \ln S_0 + \left( \mu - \frac{\sigma^2}{2} \right) t + \sigma W_t \right]$$</p><p>The GBM is technically a Markov process. The stock price hence follows a random walk and is consistent with the weak form of the efficient market hypothesis (EMH).</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Calculate stock price at time t</span><br>S = S0 * np.exp(r * t - <span class="hljs-number">1</span>/<span class="hljs-number">2</span> * sigma**<span class="hljs-number">2</span> * t + sigma * np.random.randn() * np.sqrt(t))<br></code></pre></td></tr></table></figure><p><img src="simulation.png"></p><h3 id="Probability-density-function"><a href="#Probability-density-function" class="headerlink" title="Probability density function"></a>Probability density function</h3><p>Since the exponent of $S_t$ is normally distributed, we can use the change of variable formula to calculate the probability distribution of $S_t$. Let $Z \sim \mathcal{N}(m, v)$ where the probability density function of $z$ is given by:</p><p>$$f_Z(z) = \frac{1}{\sqrt{2\pi v}} \exp \left[ -\frac{(z-m)^2}{2 v} \right]$$</p><p>We then calculate the probability density function of $x = g(z) = e^z$ using:</p><p>$$f_X(x) = f_Z(z = g^{-1}(x)) \left| \frac{dz}{dx} \right| = \frac{1}{x \sqrt{2\pi v}} \exp \left[ -\frac{(\ln x -m)^2}{2 v} \right]$$</p><p>Note that for $S_t$ the exponent is normally distributed with mean $\ln S_0 + \left( \mu - \frac{\sigma^2}{2} \right) t$ and variance $\sigma^2 t$. Hence, $S_t$ follows a log-normal distribution:</p><p>$$S_t \sim \mathcal{LN} \left[\ln S_0 + \left( \mu - \frac{\sigma^2}{2} \right) t, \sigma^2 t\right] $$</p><p><img src="probability.png"></p><h3 id="Maximum-likelihood-estimate"><a href="#Maximum-likelihood-estimate" class="headerlink" title="Maximum likelihood estimate"></a>Maximum likelihood estimate</h3><p>In order to estimate the percentage drift $\mu$ and percentage volatility $\sigma$, we use the previously calculated probability density function for log-normal distribution to obtain an expression for the log-likelihood:</p><p>$$L = - \frac{n}{2} \ln v - \frac{n}{2} \ln 2\pi - \sum_{i=1}^n \ln x_i - \sum_{i=1}^n -\frac{(\ln x_i -m)^2}{2 v}$$</p><p>Differentiate with respect to the model parameters to find the maximum likelihood (ML) estimate:</p><p>$$m = \frac{\sum_{i=1}^n \ln x_i}{n}, \quad v = \frac{\sum_{i=1}^n (\ln x_i - m)^2}{n}$$</p><p>We can use the GBM to model real financial data by looking at the General Electric stock daily data over 20 business days. </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">             High    Low   Open  Close      Volume  Adj Close<br>Date                                                         <br>2021-06-01  14.34  14.10  14.23  14.15  50276900.0  14.139239<br>2021-06-02  14.18  14.01  14.18  14.09  39936800.0  14.079286<br>2021-06-03  14.37  13.94  13.99  14.09  63163800.0  14.079286<br>2021-06-04  14.20  13.86  14.16  13.96  64071200.0  13.949385<br>2021-06-07  14.07  13.86  14.00  13.91  37349100.0  13.899423<br></code></pre></td></tr></table></figure><p>By calculating the mean and variance of the log returns, we can obtain an estimate of the risk free interest rate and volatility.</p><p>$$\ln \frac{S_t}{S_0} = \left( \mu - \frac{\sigma^2}{2} \right) t + \sigma W_t \sim \mathcal{N} \left[ \left( \mu - \frac{\sigma^2}{2} \right) t, \sigma^2 t \right]$$</p><p><img src="estimate.png"></p><h2 id="Black-Scholes-Model"><a href="#Black-Scholes-Model" class="headerlink" title="Black Scholes Model"></a>Black Scholes Model</h2><h3 id="The-Black-Scholes-Formula"><a href="#The-Black-Scholes-Formula" class="headerlink" title="The Black-Scholes Formula"></a>The Black-Scholes Formula</h3><p>The Black-Scholes call option formula is calculated by multiplying the stock price $S_t$ by the cumulative standard normal distribution. Thereafter, the net present value (NPV) of the strike price $K$ with risk-free interest rate $r$ and time to maturity $t$ is multiplied by the cumulative standard normal distribution and subtracted from the resulting value. The call option price $C$ is  therefore given by:</p><p>$$C = S_t N(d_1) - K e^{-rt} N(d_2)$$</p><p>$N(d_2)$ is the risk-adjusted probability that the option will be exercised. $N(d_1)$ is the factor by which the present value of contingent receipt of the stock exceeds the current stock price.</p><p>$$d_1 = \frac{\ln \frac{S_t}{K} + \left( r + \frac{\sigma^2}{2} \right)t}{\sigma \sqrt{t}}, \quad d_2 = d_1 - \sigma \sqrt{t}$$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Calculate the value of a call option using the Black-Scholes formula</span><br>d1 = (<span class="hljs-number">1</span> / sigma * np.sqrt(t)) * (np.log(S0/K) + (r + <span class="hljs-number">1</span>/<span class="hljs-number">2</span> * sigma**<span class="hljs-number">2</span> * t))<br>d2 = d1 - sigma * np.sqrt(t)<br>C = S0 * (norm.cdf(d1)) - np.exp(-r * t) * K * norm.cdf(d2)<br></code></pre></td></tr></table></figure><p><img src="options.png"></p><h3 id="Monte-Carlo-for-vanilla-option"><a href="#Monte-Carlo-for-vanilla-option" class="headerlink" title="Monte Carlo for vanilla option"></a>Monte Carlo for vanilla option</h3><p>Options are financial instruments that give the holder the right, but not the obligation, to buy or sell an underlying asset at a predetermined price within a given timeframe. A vanilla option is a call option or put option that has no special or unusual features. We can compare the average payoff of an option simulated with GBM with its price calculated using the Black-Scholes model.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Monte Carlo simulation</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(NUM_SIMS):<br>    stock_price = S0 * np.exp(r * t - <span class="hljs-number">1</span>/<span class="hljs-number">2</span> * sigma**<span class="hljs-number">2</span> * t + sigma * np.random.randn() * np.sqrt(t))<br>    payoff[i] = (stock_price - K) * np.exp(-r * t) <span class="hljs-keyword">if</span> stock_price &gt; K <span class="hljs-keyword">else</span> <span class="hljs-number">0</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Quantitative Finance</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Quant</tag>
      
      <tag>Finance</tag>
      
      <tag>Capital market</tag>
      
      <tag>Stock</tag>
      
      <tag>Option</tag>
      
      <tag>Modelling</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Yield Curve Construction and Analysis</title>
    <link href="/2021/07/17/yield-curve/"/>
    <url>/2021/07/17/yield-curve/</url>
    
    <content type="html"><![CDATA[<p>A yield curve is a line that plots yields (interest rates) of bonds having equal credit quality but differing maturity dates. In this article, we survey a selection of the interpolation algorithms that are in use in financial markets for construction of curves such as forward curves and yield curves. The term structure of interest rates is defined as the relationship between the yield-to-maturity on a zero coupon bond and bond’s maturity.</p><span id="more"></span><h2 id="Yield-curve-mathematics"><a href="#Yield-curve-mathematics" class="headerlink" title="Yield curve mathematics"></a>Yield curve mathematics</h2><p>For a discount or zero coupon bond, the price of an instrument now at time $0$ which pays $1$ unit of currency at time $t$ is denoted $Z(0, t)$. The inverse of this amount is denoted $C(0, t)$ and called the capitalization factor. Note that $Z(0, t)$ is decreasing in $t$ for no arbitrage. Let the time $0$ continuous compounded risk free rate for maturity $t$ be denoted $r(t)$.</p><p>$$C(0, t) = \exp(r(t)t)$$</p><p>$$Z(0,t) = \exp(-r(t)t)$$</p><p>$$r(t) = - \frac{1}{t} \ln Z(0, t)$$</p><p>In normal markets, yield curves are upwardly sloping, with longer term interest rates being higher than short term. A yield curve which is downward sloping is called inverted. A yield curve with one or more turning points is called mixed. In a stable market with reasonably liquidity, one can observe a consistent mixed shape over long periods of time.</p><blockquote><p>While normal curves point to economic expansion, downward sloping (inverted) curves point to economic recession.</p></blockquote><h2 id="Interpolation-and-bootstrap"><a href="#Interpolation-and-bootstrap" class="headerlink" title="Interpolation and bootstrap"></a>Interpolation and bootstrap</h2><p>In finance, bootstrapping is a method for constructing a (zero-coupon) fixed-income yield curve from the prices of a set of coupon-bearing products, e.g. bonds and swaps. So far we assumed that bonds trade with sufficient liquidity and as a continuum i.e. a zero coupon bond exists for every redemption date $t$. In fact, such bonds rarely trade in the market, and we need to impute such a continuum via bootstrapping.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Use quadratic interpolation for curve fitting</span><br>r = interp1d(curve_dates, zero_rates, kind=<span class="hljs-string">&#x27;quadratic&#x27;</span>)<br></code></pre></td></tr></table></figure><p><img src="bootstrap.png"></p><h2 id="Forward-rates"><a href="#Forward-rates" class="headerlink" title="Forward rates"></a>Forward rates</h2><p>The forward discount factor for the period from $t_1$ to $t_2$ at time $0$ satisfies the no arbitrage equation:</p><p>$$Z(0, t) Z(0; t_1, t_2) = Z(0, t_2)$$</p><p>The forward rate governing the period from $t_1$ to $t_2$, denoted $f(0; t_1, t_2)$, satisfies:</p><p>$$\exp(-f(0; t_1, t_2)(t_2 - t_1)) = Z(0; t_1, t_2)$$</p><p>Note that forward rates are positive and we have:</p><p>$$f(0; t_1, t_2) = -\frac{\ln Z(0, t_2) - \ln Z(0, t_1)}{t_2 - t_1} = - \frac{r_2 t_2 - r_1 t_1}{t_2 - t_1}$$</p><h2 id="Zero-curve-to-forward-curve-conversion"><a href="#Zero-curve-to-forward-curve-conversion" class="headerlink" title="Zero curve to forward curve conversion"></a>Zero curve to forward curve conversion</h2><p>Let instantaneous forward rate for a tenor of $t$ be denoted $f(t)$, we have:</p><p>$$f(t) = \frac{d}{dt} r(t)t = r(t) + r^{\prime}(t)t$$</p><p>Hence, the forward rates will lie above the yield curve when the yield curve is normal, and below the yield curve when it is inverted.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Use backward difference for numerical differentiation</span><br>f = <span class="hljs-keyword">lambda</span> t: r(t) + np.diff(r(t), prepend=r(t)[<span class="hljs-number">0</span>]) * t / dt<br></code></pre></td></tr></table></figure><h2 id="Forward-curve-to-zero-curve-conversion"><a href="#Forward-curve-to-zero-curve-conversion" class="headerlink" title="Forward curve to zero curve conversion"></a>Forward curve to zero curve conversion</h2><p>Given the forward rate function, we can find the risk free function by integrating:</p><p>$$r(t)t = \int_{0}^{t} f(s) ds = r_{i-1}t_{i-1} + \int_{t_{i-1}}^{t} f(s)ds, \quad t \in [t_{i-1}, t_i]$$</p><p>Note that the average of the instantaneous forward rate over any of our intervals $[t_{i-1}, t_i]$ is equal to the discrete forward rate for that interval.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Use dynamic programming for numerical integration</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(t)):<br>r[i] = (r[i-<span class="hljs-number">1</span>] * t[i-<span class="hljs-number">1</span>] + np.trapz([f[i-<span class="hljs-number">1</span>], f[i]], [t[i-<span class="hljs-number">1</span>], t[i]])) / t[i]<br></code></pre></td></tr></table></figure><h2 id="Bank-of-England-UK-yield-curve-data"><a href="#Bank-of-England-UK-yield-curve-data" class="headerlink" title="Bank of England UK yield curve data"></a>Bank of England UK yield curve data</h2><p>The government liability curve is based on yields on UK government bonds (gilts) and yields in the general collateral repo market. The nominal yield curves are derived from UK gilt prices and General Collateral (GC) repo rates. The real yield curves are derived from UK index-linked bond prices. Using the Fisher relationship, we are also able to estimate a term structure of inflation expectations for the United Kingdom. </p><p><img src="glc.png"></p>]]></content>
    
    
    <categories>
      
      <category>Quantitative Finance</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Quant</tag>
      
      <tag>Finance</tag>
      
      <tag>Capital market</tag>
      
      <tag>Bond</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Part IIA Engineering Tripos Revision Notes</title>
    <link href="/2021/07/16/part-iia/"/>
    <url>/2021/07/16/part-iia/</url>
    
    <content type="html"><![CDATA[<p>This is the revision notes for Part IIA of the Engineering Tripos at the University of Cambridge. The modules taken are part of Information and Computer Engineering, Electrical and Information Sciences, Instrumentation and Control.</p><span id="more"></span><p>Download the pdf version of the revision notes here:</p><ul><li><a href="Radio_Frequency_Electronics.pdf" download>3B1 Radio Frequency Electronics</a></li><li><a href="Semiconductor_Engineering.pdf" download>3B5 Semiconductor Engineering</a></li><li><a href="Signals_and_Systems.pdf" download>3F1 Signals and Systems</a></li><li><a href="Systems_and_Control.pdf" download>3F2 Systems and Control</a></li><li><a href="Statistical_Signal_Processing.pdf" download>3F3 Statistical Signal Processing</a></li><li><a href="Data_Transmission.pdf" download>3F4 Data Transmission</a></li><li><a href="Information_Theory_and_Coding.pdf" download>3F7 Information Theory and Coding</a></li><li><a href="Inference.pdf" download>3F8 Inference</a></li><li><a href="Modelling_Risk.pdf" download>3E3 Modelling Risk</a></li><li><a href="Mathematical_Methods.pdf" download>3M1 Mathematical Methods</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>Notes</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Cambridge</tag>
      
      <tag>Engineering</tag>
      
      <tag>Information</tag>
      
      <tag>Computer</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Generating Pokemon with Deep Convolutional GANs</title>
    <link href="/2020/05/06/pokemon-generation/"/>
    <url>/2020/05/06/pokemon-generation/</url>
    
    <content type="html"><![CDATA[<p>Generative Adversarial Networks (GANs) are one of the most interesting ideas in computer science today. Two models are trained simultaneously by an adversarial process. A generator learns to create images that look real, while a discriminator learns to tell real images apart from fakes. This project aims to use a deep convolutional GAN to generate Pokemons and classify their types. Visit the website at <a href="https://ziyizhu.me/pokemon-generator/">Pokemon Generator</a>.</p><span id="more"></span><p><img src="dcgan.gif"></p><h2 id="Documentation"><a href="#Documentation" class="headerlink" title="Documentation"></a>Documentation</h2><p>Code for this project can be found in <a href="https://github.com/ziyi-zhu/pokemon-generator">GitHub repository</a>.</p><h3 id="Dependencies"><a href="#Dependencies" class="headerlink" title="Dependencies"></a>Dependencies</h3><p>Install Express in the <code>root</code> directory and save it in the dependencies list. For example:</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">npm install express --save<br></code></pre></td></tr></table></figure><p>To install Express temporarily and not add it to the dependencies list:</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">npm install express --no-save<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Machine Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Node.js</tag>
      
      <tag>Javascript</tag>
      
      <tag>Python</tag>
      
      <tag>TensorFlow</tag>
      
      <tag>Machine learning</tag>
      
      <tag>GANs</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Optical Bouncer - AR Game Made for Browser</title>
    <link href="/2020/03/30/ar-browser-game/"/>
    <url>/2020/03/30/ar-browser-game/</url>
    
    <content type="html"><![CDATA[<p>Augmented reality (AR) is an interactive experience of a real-world environment where the objects that reside in the real world are enhanced by computer-generated perceptual information. This simple game uses computer vision to achieve the illusion of AR and allow players to control the game by moving real objects. This game is also built with Matter.js which is a JavaScript 2D rigid body physics engine for the web. Visit the website at <a href="https://ziyizhu.me/optical-bouncer/">Optical Bouncer</a>.</p><span id="more"></span><p><img src="gameplay.gif"></p><h2 id="Documentation"><a href="#Documentation" class="headerlink" title="Documentation"></a>Documentation</h2><p>Code for this project can be found in <a href="https://github.com/ziyi-zhu/optical-bouncer">GitHub repository</a>.</p><h3 id="Dependencies"><a href="#Dependencies" class="headerlink" title="Dependencies"></a>Dependencies</h3><p>Install Express and Matter.js in the <code>root</code> directory and save it in the dependencies list. For example:</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">npm install --save express matter-js<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Computer Vision</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Node.js</tag>
      
      <tag>Javascript</tag>
      
      <tag>Matter.js</tag>
      
      <tag>Computer vision</tag>
      
      <tag>AR</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Virus Simulation with Quadtree Implementation in Javascript</title>
    <link href="/2020/03/24/virus-simulation/"/>
    <url>/2020/03/24/virus-simulation/</url>
    
    <content type="html"><![CDATA[<p>The outbreak of the respiratory virus in China has caused an unprecedented global response over the past few months. The spread of a virus can be affected by several factors such as the extent of social distancing and incubation periods of the virus. This project attempts to model the spread of such a virus while impelementing a quadtree data structure to efficiently store data of points on a two-dimensional space. Visit the website at <a href="https://ziyizhu.me/virus-simulator/">Virus Simulator</a>.</p><span id="more"></span><p><img src="spread.gif"></p><h2 id="Documentation"><a href="#Documentation" class="headerlink" title="Documentation"></a>Documentation</h2><p>Code for this project can be found in <a href="https://github.com/ziyi-zhu/virus-simulator">GitHub repository</a>.</p><h3 id="Dependencies"><a href="#Dependencies" class="headerlink" title="Dependencies"></a>Dependencies</h3><p>Install Express in the <code>root</code> directory and save it in the dependencies list. For example:</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">npm install express --save<br></code></pre></td></tr></table></figure><p>To install Express temporarily and not add it to the dependencies list:</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">npm install express --no-save<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Others</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Node.js</tag>
      
      <tag>Javascript</tag>
      
      <tag>Processing</tag>
      
      <tag>Data analysis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Part IB Engineering Tripos Revision Notes</title>
    <link href="/2020/03/24/part-ib/"/>
    <url>/2020/03/24/part-ib/</url>
    
    <content type="html"><![CDATA[<p>This is the revision notes for Part IB of the Engineering Tripos at the University of Cambridge. The modules taken are part of Information and Computer Engineering, Electrical and Information Sciences, Instrumentation and Control.</p><span id="more"></span><p>Download the pdf version of the revision notes here:</p><ul><li><a href="linear-systems-and-control.pdf" download>Paper 6 Linear Systems and Control</a></li><li><a href="signal-and-data-analysis.pdf" download>Paper 6 Signal and Data Analysis</a></li><li><a href="communications.pdf" download>Paper 6 Communications</a></li><li><a href="linear-algebra.pdf" download>Paper 7 Linear Algebra</a></li><li><a href="probability.pdf" download>Paper 7 Probability</a></li><li><a href="vector-calculus.pdf" download>Paper 7 Vector Calculus</a></li><li><a href="engineer-in-business.pdf" download>Paper 8 Engineer in Business</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>Notes</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Cambridge</tag>
      
      <tag>Engineering</tag>
      
      <tag>Information</tag>
      
      <tag>Computer</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Visualization for Image Processing Algorithms</title>
    <link href="/2020/03/17/image-processing-visualization/"/>
    <url>/2020/03/17/image-processing-visualization/</url>
    
    <content type="html"><![CDATA[<p>In image processing, a kernel, convolution matrix, or mask is a small matrix. It is used for blurring, sharpening, embossing, edge detection, and other useful algorithms for feature extraction and matching. This process is accomplished by doing a two dimensional convolution between a kernel and an image. This project aims to visualize the process of such algorithms. See the algorithms in action on <a href="https://ziyizhu.me/image-processing-visualizer/">Image Processing Visuailizer</a>.</p><span id="more"></span><p><img src="original.jpg"></p><h2 id="Image-processing-algorithms-for-feature-extraction"><a href="#Image-processing-algorithms-for-feature-extraction" class="headerlink" title="Image processing algorithms for feature extraction"></a>Image processing algorithms for feature extraction</h2><h3 id="1D-edge-detection"><a href="#1D-edge-detection" class="headerlink" title="1D edge detection"></a>1D edge detection</h3><p>A broad overview of 1D edge detection is to convolve the signal $I(x)$ with a <strong>Gaussian kernel</strong> $g_\sigma(x)$ and call the smoothed signal $s(x)$. Then compute the derivative $s^{‘}(x)$ and find its maxima and minima. Use thresholding on the magnitude of extrema to mark edges.</p><p>$$g_{\sigma}(x) = \frac{1}{\sigma\sqrt{2\pi}} e^{-\frac{x^2}{2\sigma^2}}$$ </p><p>$$s(x) = g_{\sigma}(x) * I(x) = \int_{-\infty}^{\infty} g_{\sigma}(u)I(x-u)du = \int_{-\infty}^{\infty} g_{\sigma}(x-u)I(u)du$$</p><p><img src="edge_detection.png"></p><p>The differentiation is also performed by a 1D convolution. However, we can compute $s^{‘}(x)$ by convolving only once using the <strong>derivative theorem of convolution</strong>:</p><p>$$s^{‘}(x) = \frac{d}{dx} \left[ g_{\sigma}(x) * I(x) \right] = g_{\sigma}^{‘}(x) * I(x)$$</p><p><img src="edge_detection_simplified.png"></p><p>Looking for maxima and minima of $s^{‘}(x)$ is the same as looking for zero-crossings of $s^{‘’}(x)$. In many implementations of edge detection algorithms, the signal is convolved with the <strong>Laplacian of a Gaussian</strong> (LoG) $g_{\sigma}^{‘’}$:</p><p>$$s^{‘’}(x) = g_{\sigma}^{‘’} * I(x)$$</p><p><img src="zero_crossings.png"></p><p>In multi-scale edge detection, using a small $\sigma$ brings out all the edges. As $\sigma$ increases, the signal is smoothed more and more and only the central edge survives. The amount of smoothing controls the scale at which we analyse the image. Fine scale edge detection is particularly sensitive to noise.</p><h3 id="2D-edge-detection"><a href="#2D-edge-detection" class="headerlink" title="2D edge detection"></a>2D edge detection</h3><p>The 1D edge detection scheme can be extended to work in two dimensions. First we smooth the image $I(x, y)$ by convolving with a 2D Gaussian $G_{\sigma}(x, y)$:</p><p>$$G_{\sigma}(x, y) = \frac{1}{2\pi\sigma^2} e^{-\frac{x^2+y^2}{2\sigma^2}}$$ </p><p>$$S(x, y) = G_{\sigma}(x, y) * I(x, y) = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} G_{\sigma}(u, v)I(x-u, y-v)dudv$$</p><p>The next step is to find the gradient of the smoothed image $S(x, y)$ at every pixel:</p><p>$$\Delta S = \Delta (G_{\sigma} * I) = \begin{bmatrix} \frac{\partial (G_{\sigma} * I)}{\partial x} \\ \frac{\partial (G_{\sigma} * I)}{\partial y} \end{bmatrix} = \begin{bmatrix} \frac{\partial G_{\sigma}}{\partial x} * I \\ \frac{\partial G_{\sigma}}{\partial y} * I \end{bmatrix}$$</p><p>The next stage of the edge detection algorithm is non-maximal suppression. Edge elements, or edgels, are placed at locations where $|\Delta S|$ is greater than local values of $|\Delta S|$ in the directions $\pm \Delta S$. This aims to ensure that all edgels are located at ridge-points of the surface $|\Delta S|$. Subsequently, the edgels are thresholded, so that only those with $|\Delta S|$ above a certain value are retained.</p><p>An alternative approach to edge detection is to find zero-crossings of $\Delta^{2}G_{\sigma} * I$, where $\Delta^{2}G_{\sigma}$ is the Laplacian of $G_{\sigma}$.</p><p><img src="gaussian.png"></p><h3 id="Implementation-details"><a href="#Implementation-details" class="headerlink" title="Implementation details"></a>Implementation details</h3><p>In practice, the image and filter kernels are discrete quantities and the convolutions are performed as truncated summations:</p><p>$$S(x, y) = \sum_{u=-n}^{n} \sum_{u=-n}^{n} G_{\sigma}(u, v)I(x-u, y-v)$$</p><p><img src="kernel.png"></p><p>For acceptable accuracy, kernels are generally truncated so that the discarded samples are less than $1/1000$ of the peak value. The 2D convolutions would appear to be computationally expensive. However, they can be decomposed into two 1D convolutions:</p><p>$$G_{\sigma}(x, y) * I(x, y) = g_{\sigma}(x) * \left[g_{\sigma}(y) * I(x, y) \right]$$</p><p>Differentiation of the smoothed image is also implemented with a discrete convolution. By considering the Taylor-series expansion of $S(x, y)$ it is easy to show that a simple finite-difference approximation to the first-order spatial derivative of $S(x, y)$ is given by:</p><p>$$\frac{\partial S}{\partial x} = \frac{S(x+1, y) - S(x-1, y)}{2}$$</p><p>This is equivalent to convolving the rows of image samples, $S(x, y)$, with the kernel:</p><p>$$\begin{bmatrix} 1/2 &amp; 0 &amp; -1/2 \end{bmatrix}$$</p><h3 id="Corner-detection"><a href="#Corner-detection" class="headerlink" title="Corner detection"></a>Corner detection</h3><p>In an image, a corner is characterized by an intensity discontinuity in two directions. This discontinuity can be detected using <strong>correlation</strong>. The normalized <strong>cross-correlation</strong> function measures how well an image patch $P(x, y)$ matches other portions of the image, $I(x, y)$, as it is shifted from its original location. It entails sliding the patch over the image, computing the sum of the products of the pixels and normalizing the result:</p><p>$$c(x, y) = \frac{\sum_{u=-n}^{n} \sum_{u=-n}^{n} P(u, v)I(x+u, y+v)}{\sqrt{\sum_{u=-n}^{n} \sum_{u=-n}^{n} P^{2}(u, v) \sum_{u=-n}^{n} \sum_{u=-n}^{n} I^{2}(x+u, y+v)}}$$</p><p>A patch which has a well-defined peak in its correlation function can be classified as a “corner”.</p><p><img src="corner_detection.png"></p><p>A practical corner detection algorithm calculates change in intensity in direction $\mathbf{n}$ and smooths the result by convolution with a Gaussian kernel:</p><p>$$I_{n} \equiv \Delta I(x, y) \cdot \mathbf{n} \equiv \begin{bmatrix} I_{x} &amp; I_{y} \end{bmatrix}^{T} \cdot \mathbf{n} \equiv \begin{bmatrix} \frac{\partial I}{\partial x} &amp; \frac{\partial I}{\partial y} \end{bmatrix}^{T} \cdot \mathbf{n}$$</p><p>$$I_{n}^{2} = \frac{\mathbf{n}^{T} \Delta I \Delta I^{T} \mathbf{n}}{\mathbf{n}^{T} \mathbf{n}} = \frac{\mathbf{n}^{T} \begin{bmatrix} I_{x}^{2} &amp; I_{x}I_{y} \\ I_{x}I_{y} &amp; I_{y}^{2} \end{bmatrix} \mathbf{n}}{\mathbf{n}^{T} \mathbf{n}}$$</p><p>$$C_{n}(x, y) = G_{\sigma}(x, y) * I_{n}^{2} = \frac{\mathbf{n}^{T} \begin{bmatrix} \langle I_{x}^{2}\rangle &amp; \langle I_{x}I_{y}\rangle \\ \langle I_{x}I_{y}\rangle &amp; \langle I_{y}^{2}\rangle \end{bmatrix} \mathbf{n}}{\mathbf{n}^{T} \mathbf{n}} \equiv \frac{\mathbf{n}^{T} A \mathbf{n}}{\mathbf{n}^{T} \mathbf{n}}$$</p><p>Elementary eigenvector theory shows that $\lambda_{1} \leq C_{n}(x, y) \leq \lambda_{2}$ where $\lambda_{1}$ and $\lambda_{2}$ are the eigenvalues of $A$. Therefore, image structure around each pixel can be classified by looking at the eigenvalues:</p><ol><li>No structure (smooth variation): $\lambda_{1} \approx \lambda_{2} \approx 0$</li><li>1D structure (edge): $\lambda_{1} \approx 0$, $\lambda_{2}$ large (normal to edge)</li><li>2D structure (corner): $\lambda_{1}$ and $\lambda_{2}$ both large and distinct</li></ol><p>Corners are most useful for tracking in image sequences or matching in stereo pairs.</p><h3 id="Blob-detection"><a href="#Blob-detection" class="headerlink" title="Blob detection"></a>Blob detection</h3><p>A blob is an area of uniform intensity in the image. The minimum of the resulting response from the scale-normalised Laplacian of the Gaussian at the correct scale localises the centre of the dots:</p><p><img src="blob_detection.png"></p><p>The size of the blob detected depends on the sigma of the detector used. As the sigma is increased, larger and larger image features are detected, ranging from small boxes to entire buildings. The (scale-normalised) Laplacian of a Gaussian as recorded at a particular location is a smooth function over scale, with definite peaks or troughs. These maxima and minima occur at the centre of blobs whilst the scale defines its size.</p><p><img src="scale_space.png"></p><p>The <strong>Difference of Gaussians</strong> (DoG) is a blob detector. It is calculated as the difference of two Gaussians, which approximates the scalenormalised Laplacian of a Gaussian.</p><p>$$G(x, y, k\sigma) - G(x, y, \sigma) \approx (k - 1)\sigma^{2} \Delta^{2} G(x, y, \sigma)$$</p><h2 id="Kernels-used-for-image-processing-algorithms"><a href="#Kernels-used-for-image-processing-algorithms" class="headerlink" title="Kernels used for image processing algorithms"></a>Kernels used for image processing algorithms</h2><p>Image Processing Visuailizer features a collection of commonly used kernels for image processing and feature extraction. In practice, the kernels are convoluted across the image to produce the desired output.</p><p><img src="algorithms.jpg"></p><h3 id="Box-blur"><a href="#Box-blur" class="headerlink" title="Box blur"></a>Box blur</h3><p>A box blur (also known as a box linear filter) is a spatial domain linear filter in which each pixel in the resulting image has a value equal to the average value of its neighbouring pixels in the input image. It is a form of low-pass (“blurring”) filter. </p><p>$$\mathbf{G} = \frac{1}{9} \begin{bmatrix}1 &amp; 1 &amp; 1\\1 &amp; 1 &amp; 1\\1 &amp; 1 &amp; 1\end{bmatrix} * \mathbf{A}$$ </p><p>Box blurs are frequently used to approximate a Gaussian blur. By the central limit theorem, repeated application of a box blur will approximate a Gaussian blur.</p><h3 id="Gaussian-blur"><a href="#Gaussian-blur" class="headerlink" title="Gaussian blur"></a>Gaussian blur</h3><p>In image processing, a Gaussian blur (also known as Gaussian smoothing) is the result of blurring an image by a Gaussian function. Mathematically, applying a Gaussian blur to an image is the same as convolving the image with a Gaussian function. This is also known as a two-dimensional Weierstrass transform. </p><p>$$G(x,y) = \frac{1}{2\pi\sigma^2} e^{-\frac{x^2+y^2}{2\sigma^2}}$$ </p><p>Gaussian smoothing is also used as a pre-processing stage in computer vision algorithms in order to enhance image structures at different scales.</p><h3 id="Sobel-operator"><a href="#Sobel-operator" class="headerlink" title="Sobel operator"></a>Sobel operator</h3><p>The operator uses two 3×3 kernels which are convolved with the original image to calculate approximations of the derivatives – one for horizontal changes, and one for vertical. </p><p>$$\mathbf{G}_x = \begin{bmatrix}+1 &amp; 0 &amp; -1\\+2 &amp; 0 &amp; -2\\+1 &amp; 0 &amp; -1\end{bmatrix} * \mathbf{A}$$<br>$$\mathbf{G}_y = \begin{bmatrix}+1 &amp; +2 &amp; +1\\0 &amp; 0 &amp; 0\\-1 &amp; -2 &amp; -1\end{bmatrix} * \mathbf{A}$$</p><p>The x-coordinate is defined here as increasing in the “right”-direction, and the y-coordinate is defined as increasing in the “down”-direction. At each point in the image, the resulting gradient approximations can be combined to give the gradient magnitude and direction, using: </p><p>$$\mathbf{G} = \sqrt{\mathbf{G}_x^2 + \mathbf{G}_y^2}$$<br>$$\mathbf{\Theta} = \arctan{\frac{\mathbf{G}_y}{\mathbf{G}_x}}$$</p><h3 id="Prewitt-operator"><a href="#Prewitt-operator" class="headerlink" title="Prewitt operator"></a>Prewitt operator</h3><p>The operator uses two 3×3 kernels which are convolved with the original image to calculate approximations of the derivatives – one for horizontal changes, and one for vertical. </p><p>$$\mathbf{G}_x = \begin{bmatrix}+1 &amp; 0 &amp; -1\\+1 &amp; 0 &amp; -1\\+1 &amp; 0 &amp; -1\end{bmatrix} * \mathbf{A}$$<br>$$\mathbf{G}_y = \begin{bmatrix}+1 &amp; +1 &amp; +1\\0 &amp; 0 &amp; 0\\-1 &amp; -1 &amp; -1\end{bmatrix} * \mathbf{A}$$ </p><h3 id="Canny-edge-detector"><a href="#Canny-edge-detector" class="headerlink" title="Canny edge detector"></a>Canny edge detector</h3><p>The algorithm takes the output of a Sobel operator and categorizes the continuous gradient directions into a small set of discrete directions, and then moves a 3x3 filter over the output of the previous step (that is, the edge strength and gradient directions). At every pixel, it suppresses the edge strength of the centre pixel (by setting its value to 0) if its magnitude is not greater than the magnitude of the two neighbours in the gradient direction.</p><h2 id="Documentation"><a href="#Documentation" class="headerlink" title="Documentation"></a>Documentation</h2><p>Code for this project can be found in <a href="https://github.com/ziyi-zhu/image-processing-visualizer">GitHub repository</a>.</p><h3 id="Dependencies"><a href="#Dependencies" class="headerlink" title="Dependencies"></a>Dependencies</h3><p>Install Express in the <code>root</code> directory and save it in the dependencies list. For example:</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">npm install express --save<br></code></pre></td></tr></table></figure><p>To install Express temporarily and not add it to the dependencies list:</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">npm install express --no-save<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Computer Vision</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Node.js</tag>
      
      <tag>Javascript</tag>
      
      <tag>Computer vision</tag>
      
      <tag>Computer graphics</tag>
      
      <tag>Image processing</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Autonomous Robot Navigation Using Computer Vision</title>
    <link href="/2020/03/02/cv-robot-navigation/"/>
    <url>/2020/03/02/cv-robot-navigation/</url>
    
    <content type="html"><![CDATA[<p>Autonomous navigation is widely used in robotics or any other mobile device as the ability to navigate in their environment is crucial for safe and successful operations. Computer vision is one of the most popular methods in autonomous navigation as the algorithms can extract visual features and analyze complex situations in a variety of environment. This project aims to explore different algorithmic approaches to autonomous navigation and design a self-navigating robot for rescue tasks in a tunnel-like environment.</p><span id="more"></span><p><img src="output.gif"></p><h2 id="Introduction-to-robot-navigation"><a href="#Introduction-to-robot-navigation" class="headerlink" title="Introduction to robot navigation"></a>Introduction to robot navigation</h2><p>Navigation can be defined as the combination of the three fundamental competencies:</p><ol><li>Self-localisation</li><li>Path planning</li><li>Map-building and map interpretation</li></ol><p>Robot localization denotes the robot’s ability to establish its position and orientation within the frame of reference. Path planning is effectively an extension of localisation, in that it requires the determination of the robot’s current position and a position of a goal location, both within the same frame of reference or coordinates. Map building can be in the shape of a metric map or any notation describing locations in the robot frame of reference.</p><h2 id="Basic-colour-detection-with-OpenCV"><a href="#Basic-colour-detection-with-OpenCV" class="headerlink" title="Basic colour detection with OpenCV"></a>Basic colour detection with OpenCV</h2><p>Vision-based navigation or optical navigation uses computer vision algorithms and optical sensors to extract the visual features required to the localization in the surrounding environment. The general idea of colour detection is to apply a threshold mask to the image and remove all the pixels that are outside the range of the specified colour. Moreover, it is easier to work in HSV colour space as normally we would like to select pixels with a certain hue but with less constraint on their saturation and value.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Threshold of green in HSV space </span><br>lower = np.array([<span class="hljs-number">40</span>, <span class="hljs-number">40</span>, <span class="hljs-number">40</span>]) <br>upper = np.array([<span class="hljs-number">60</span>, <span class="hljs-number">255</span>, <span class="hljs-number">255</span>])<br><br><span class="hljs-comment"># Convert the BGR color space of image to HSV color space </span><br>hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV) <br><br><span class="hljs-comment"># Mask out any non-essential part of the frame</span><br>hsv = cv2.bitwise_and(hsv, hsv, mask=mask)<br><br><span class="hljs-comment"># Prepare the mask to overlay and extract pixels within the threshold</span><br>thresh = cv2.inRange(hsv, lower, upper)<br></code></pre></td></tr></table></figure><p>After the coloured pixels are selected, there may be some noise in the image since the result of the colour detection algorithm depends strongly on the lighting condition as well as camera settings. Therefore, a series of actions is needed to filter out the noise and make the algorithm more robust against environmental changes.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Perform a series of erosions and dilations to remove</span><br><span class="hljs-comment"># any small blobs of noise from the thresholded image</span><br>thresh = cv2.erode(thresh, <span class="hljs-literal">None</span>, iterations=<span class="hljs-number">1</span>)<br>thresh = cv2.dilate(thresh, <span class="hljs-literal">None</span>, iterations=<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><p>After the coloured pixels are extracted from the original frame, we need an algorithm to determine the location of each blob of pixels. Different methods of blob detection can be used including the connected-component analysis, which is an algorithmic application of graph theory, where subsets of connected components are uniquely labelled based on a given heuristic. Alternatively, OpenCV has a built-in simple blob detector which works well for quick and accurate detection.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Set up the detector with custom parameters</span><br>params = cv2.SimpleBlobDetector_Params()<br>params.filterByArea = <span class="hljs-literal">True</span><br>params.minArea = <span class="hljs-number">30</span><br>params.maxArea = <span class="hljs-number">1000</span><br>params.filterByCircularity = <span class="hljs-literal">False</span><br>params.filterByColor = <span class="hljs-literal">False</span><br>params.filterByConvexity = <span class="hljs-literal">False</span><br>params.filterByInertia = <span class="hljs-literal">False</span><br><br>detector = cv2.SimpleBlobDetector_create(params)<br><br><span class="hljs-comment"># Detect blobs and save keypoints as np array</span><br>kps = detector.detect(thresh)<br></code></pre></td></tr></table></figure><p>Note that the <code>minArea</code> and <code>maxArea</code> of the blobs need to be specified for the detector to function properly. The area of the blobs may depend on the resolution of the image. Now that the locations of each blob are obtained, we need to work out the location and orientation of the robot based on the information we get from these key points.</p><p><img src="detection.jpg"></p><h2 id="Algorithmic-approach-to-self-localisation"><a href="#Algorithmic-approach-to-self-localisation" class="headerlink" title="Algorithmic approach to self-localisation"></a>Algorithmic approach to self-localisation</h2><p>In linear algebra, a rotation matrix is a matrix that is used to perform a rotation in Euclidean space.</p><p>$$\boldsymbol{R} = \begin{bmatrix} \cos{\theta} &amp; -\sin{\theta} \\ \sin{\theta} &amp; cos{\theta} \\ \end{bmatrix}$$</p><p>The approach of localising the robot is to paste a label on top of it with magenta squares at three corners of the paper. Once we retrieve the keypoints from the image, we can work out the edges and the diagonal of the label and with simple sorting and comparison, the centre position vector and top left corner of the label can be obtained and stored in variables. A 45-degree rotation matrix then allows the orientation of the robot to be computed by rotating the vector pointing from the centre position to the top left corner by 45 degrees.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Create a 45 degree rotation matrix</span><br>theta = np.radians(<span class="hljs-number">45</span>)<br>c, s = np.cos(theta), np.sin(theta)<br>R = np.array(((c,-s), (s, c)))<br><br><span class="hljs-comment"># Rotate the diagonal vector</span><br>dirn = R.dot(top_left - pos)<br></code></pre></td></tr></table></figure><p>In practice, a QR code can also be pasted on top of the robot in order to find the location and orientation of the robot with the ZBar module in python. However, this requires cameras with good quality and resolution to consistently detect the QR code.</p><p><img src="localisation.jpg"></p><h2 id="Robot-control-with-Arduino"><a href="#Robot-control-with-Arduino" class="headerlink" title="Robot control with Arduino"></a>Robot control with Arduino</h2><p>The software system consists of two main programs:</p><ol><li>C++ program is uploaded to the Arduino Uno Wifi Rev 2 with Adafruit<br>Motor Shield for servo and motor control.</li><li>Computer vision program is written in python for robot navigation and sequence control.</li></ol><p>For the computer vision program, OpenCV is used for real-time image processing and object detection. The communication between Arduino and workstation is realized using the built-in Wifi function and through HTTP requests. Arduino receives and analyses the instruction and controls the robot movement according to the angle and distance from the calculated target point. Subsequently, functions for grabbing and dropping victims are called when the respective target points are reached.</p><p><img src="side.jpg"></p><h3 id="Pinout"><a href="#Pinout" class="headerlink" title="Pinout"></a>Pinout</h3><p>Arduino Wifi Rev 2 is used with the Adafruit motor shield for motor and servo control:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c++">Adafruit_MotorShield AFMS = <span class="hljs-built_in">Adafruit_MotorShield</span>(); <br></code></pre></td></tr></table></figure><p>The pintout for Arduino can ba changed in <code>arduino/Bin.ino</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> led_abr = <span class="hljs-number">2</span>;<br>myservo.<span class="hljs-built_in">attach</span>(<span class="hljs-number">9</span>);       <span class="hljs-comment">// attaches the servo on pin 9 to the servo object</span><br></code></pre></td></tr></table></figure><p>Servo 2 on the Adafruit shield corresponds to pin 9 on the Arduino.</p><h3 id="Wifi"><a href="#Wifi" class="headerlink" title="Wifi"></a>Wifi</h3><p>The network SSID name and network password need to be specified in <code>arduino/Bin.ino</code> for HTTP requests:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">char</span> ssid[] = SECRET_SSID;        <span class="hljs-comment">// your network SSID (name)</span><br><span class="hljs-keyword">char</span> pass[] = SECRET_PASS;        <span class="hljs-comment">// your network password (use for WPA, or use as key for WEP)</span><br><span class="hljs-keyword">int</span> keyIndex = <span class="hljs-number">0</span>;                 <span class="hljs-comment">// your network key Index number (needed only for WEP)</span><br></code></pre></td></tr></table></figure><h2 id="Robot-design-and-hardware"><a href="#Robot-design-and-hardware" class="headerlink" title="Robot design and hardware"></a>Robot design and hardware</h2><p>The claw mechanism consists of an electric motor for opening and closing of the claw and a servo for the upward and downward motion. An Infrared receiver is used for victim health detection and two Optoswitches are used for line-following. </p><p>Our initial plan was to detect the distance of the robot from victims using an ultrasonic sensor. However, since the computer vision algorithm can also detect distances to a desirable accuracy, we decided not to use the sensor. After experimenting with the line-following circuit, we decided to abandon this part of the program as well and rely solely on computer vision for all robot controls and movement. This results in a simple and elegant code structure but causes problems in the end due to the malfunction of the camera in the actual competition.</p><p><img src="front.jpg"></p><h2 id="Challenges-and-next-steps"><a href="#Challenges-and-next-steps" class="headerlink" title="Challenges and next steps"></a>Challenges and next steps</h2><p>Our robot had a poor performance during the competition due to the malfunction of the camera as the exposure is too high for the robot to be accurately<br>located. We suspect the reason to be the shadows cast by people surrounding the table causing the camera to increase the exposure, resulting in abnormally<br>desaturated colour at the centre of the table which is exposed to direct lighting from the ceiling. This is not a difficult problem to address as the tolerance for colour detection can be easily adjusted. However, since it was the first time we ever encountered this problem, we did not manage to solve the issue on the spot and the time eventually ran out.</p><p>In conclusion, autonomous robot navigation using computer vision remains a very challenging problem and requires more robust algorithms with testing in a variety of conditions to validate the safety and reliability of the system. Throughout the course of this project, we made a valid attempt to tackle these issues and achieved applaudable results in the end despite some imperfections in our system. It is important to be open-minded and consider factors that might be affecting these computer vision systems in a different environment so that they can survive in the real world where, arguably, nothing is predictable.</p><h2 id="Documentation"><a href="#Documentation" class="headerlink" title="Documentation"></a>Documentation</h2><p>Code for this project can be found in <a href="https://github.com/ziyi-zhu/cv_robot_navigation">GitHub repository</a>.</p><h3 id="Dependencies"><a href="#Dependencies" class="headerlink" title="Dependencies"></a>Dependencies</h3><p>Install requests from PyPI:</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">sudo pip install requests<br></code></pre></td></tr></table></figure><p>Install OpenCV from GitHub source.</p><h2 id="Demo"><a href="#Demo" class="headerlink" title="Demo"></a>Demo</h2><p>Video demo of the robot can be found on <a href="https://youtu.be/kYkNHKw41CQ">Youtube channel</a>.</p>]]></content>
    
    
    <categories>
      
      <category>Computer Vision</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Computer vision</tag>
      
      <tag>OpenCV</tag>
      
      <tag>IoT</tag>
      
      <tag>Control</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Waste Collection and Management Using IoT and Machine Learning</title>
    <link href="/2020/01/25/smart-waste/"/>
    <url>/2020/01/25/smart-waste/</url>
    
    <content type="html"><![CDATA[<p>Having gone through projects available for Hack Cambridge 101, we are inspired by the Smart Waste challenge put forwarded by Reply. This is because current waste collection system is rather inefficient and a lot of resources has been wasted during the recycling process. Therefore, this project aims to address such urgent need for improvement in this sector.</p><span id="more"></span><p><img src="bin.jpg"></p><p>Our system has a number of key functions:</p><ul><li>Classifies incoming waste into categories (Recyclable/Organic)</li><li>Detects whether the bin is full</li><li>Optimizes waste collection routes</li></ul><h2 id="Hardware-design"><a href="#Hardware-design" class="headerlink" title="Hardware design"></a>Hardware design</h2><p>For the hardware, we started by building a bin using a cardboard box. Then we attached an Arduino board to the box which acts as the main control system. A servo motor, an ultrasonic sensor, a camera and a LED were also installed.</p><h3 id="Arduino-wiring"><a href="#Arduino-wiring" class="headerlink" title="Arduino wiring"></a>Arduino wiring</h3><p><img src="circuit.jpg"></p><h3 id="Pinout"><a href="#Pinout" class="headerlink" title="Pinout"></a>Pinout</h3><p>The pintout for Arduino can ba changed in <code>arduino/Bin.ino</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> trigPin = <span class="hljs-number">9</span>;<br><span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> echoPin = <span class="hljs-number">10</span>;<br><span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> ledPin = <span class="hljs-number">13</span>;<br><span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> buttonPin = A2;<br></code></pre></td></tr></table></figure><h3 id="Camera"><a href="#Camera" class="headerlink" title="Camera"></a>Camera</h3><p>Spy camera is used for Computer Vision.</p><p><img src="camera.jpg"></p><h3 id="Sensor"><a href="#Sensor" class="headerlink" title="Sensor"></a>Sensor</h3><p>An ultrasonic sensor is used to detect the capacity of the bin.</p><p><img src="sensor.jpg"></p><h2 id="Software-control-and-image-recognition"><a href="#Software-control-and-image-recognition" class="headerlink" title="Software control and image recognition"></a>Software control and image recognition</h2><p>In terms of the software, Arduino code is used to control all components. A Keras model detects whether the object is recyclable. A python API was also built to calculate the optimized route and plot out the route on Google map.</p><h3 id="Dependencies"><a href="#Dependencies" class="headerlink" title="Dependencies"></a>Dependencies</h3><p>Install Keras from PyPI:</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">sudo pip install Keras<br></code></pre></td></tr></table></figure><p>Install TensorFlow and OpenCV from GitHub source.</p><h2 id="Demo"><a href="#Demo" class="headerlink" title="Demo"></a>Demo</h2><p>Connect the machine to Arduino and run <code>python/predict.py</code>.</p><h3 id="Recycling-with-computer-vision"><a href="#Recycling-with-computer-vision" class="headerlink" title="Recycling with computer vision"></a>Recycling with computer vision</h3><p>Recyclable wastes will be dropped inside the bin.</p><p><img src="bag.gif"><br><img src="can.gif"></p><p>Non-recyclable wastes will be dropped outside the bin.</p><p><img src="banana.gif"><br><img src="orange.gif"></p><h3 id="Bin-capacity-detection"><a href="#Bin-capacity-detection" class="headerlink" title="Bin capacity detection"></a>Bin capacity detection</h3><p>If the bin is full, the green LED will light up.</p><p><img src="full.gif"></p><h3 id="Route-planning-with-OptimoRoute-and-Google-Map-Services"><a href="#Route-planning-with-OptimoRoute-and-Google-Map-Services" class="headerlink" title="Route planning with OptimoRoute and Google Map Services"></a>Route planning with OptimoRoute and Google Map Services</h3><p>When the bin is full, its address will be uploaded and order for waste pick up will be submitted to the OptimoRoute website. The best route can be obtained from API and plotted using Google Map.</p><p><img src="route.png"></p><h2 id="Lessons-learned"><a href="#Lessons-learned" class="headerlink" title="Lessons learned"></a>Lessons learned</h2><p>The biggest challenge we met was due to the poor quality of the camera. We initially trained the ML model using high-quality photo datasets from Imagenet. However, this didn’t work well initially as the photos collected using the spy camera were of low quality, contrast and saturation. We recognized the problem and manually collected another dataset using the spy camera. In the end, the accuracy reached around 90%. Higher accuracy can be achieved using a better camera.</p><h2 id="What’s-next"><a href="#What’s-next" class="headerlink" title="What’s next"></a>What’s next</h2><p>The core of the project is the ML model. We only had time to collect around 100 photos using the spy camera, if we had more time we could have collected more photos so that we have a larger training set. We expect this to improve its classification accuracy. The concept and the technology developed can be implemented on a large scale in urban regions, where we envision IoT enabled bins to be used in parks, public areas and homes. These devices will enable more efficient waste collection methods to be used by the council and are expected to greatly reduce the resources needed to collect public wastes. </p>]]></content>
    
    
    <categories>
      
      <category>Machine Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>IoT</tag>
      
      <tag>TensorFlow</tag>
      
      <tag>Machine learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hardware and Software for Capturing HDR Light Fields</title>
    <link href="/2019/09/02/hdr-lf-capture/"/>
    <url>/2019/09/02/hdr-lf-capture/</url>
    
    <content type="html"><![CDATA[<p>This project aims to design a system that captures HDR light fields to generate image-based 3D reconstruction for display on the HDR multi-focal stereoscope. The setup consists of an Arduino used to control the Stepper Motor and a Raspberry Pi used to send instructions to the Arduino and capture/receive images from the camera.</p><span id="more"></span><p><img src="header.jpg"></p><h2 id="Hardware-design"><a href="#Hardware-design" class="headerlink" title="Hardware design"></a>Hardware design</h2><h3 id="Arduino-wiring"><a href="#Arduino-wiring" class="headerlink" title="Arduino wiring"></a>Arduino wiring</h3><p><img src="arduino.jpg"></p><p>The Stepper Driver used in this setup is DQ542MA and the Stepper Motor used is NEMA 17 42BYGH-W811.</p><p>Connection between Stepper Driver and Arduino:</p><ul><li>PUL+ from Driver to Arduino PIN7</li><li>PUL- from Driver to Arduino PIN5</li><li>DIR+ from Driver to Arduino PIN7</li><li>DIR- from Driver to Arduino PIN6</li><li>ENBL+ from Driver to Arduino PIN7</li></ul><p>Connection between Stepper Driver and Stepper Motor:</p><ul><li>A+ from Driver to Stepper BLACK wire</li><li>A- from Driver to Stepper GREEN wire</li><li>B+ from Driver to Stepper RED wire</li><li>B- from Driver to Stepper BLUE wire</li></ul><p>Connection between Button and Arduino:</p><ul><li>Button YELLOW wire to Arduino PINA0</li></ul><h3 id="DIP-switch-setting"><a href="#DIP-switch-setting" class="headerlink" title="DIP switch setting"></a>DIP switch setting</h3><p><img src="switch.jpg"></p><p>The first three bits of the DIP switch are used to set the dynamic current. For an output current of 2.37A, SW 1, 2, 3 is set to OFF, OFF, ON.</p><p>Micro step resolution is set by the last four bits of the DIP switch. For 1600 pulse per revolution, SW 5, 6, 7, 8 is set to OFF, OFF, ON, ON.</p><h3 id="Power-supply"><a href="#Power-supply" class="headerlink" title="Power supply"></a>Power supply</h3><p><img src="battery.jpg"></p><p>The power supply for the Stepper Driver is 18V (3 parallel sets of 2 9V batteries in series).</p><h2 id="Serial-communication-with-Python"><a href="#Serial-communication-with-Python" class="headerlink" title="Serial communication with Python"></a>Serial communication with Python</h2><h3 id="Dependencies"><a href="#Dependencies" class="headerlink" title="Dependencies"></a>Dependencies</h3><p>Installing libgphoto2:</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">sudo apt-get install libgphoto2-dev<br></code></pre></td></tr></table></figure><p>Installing python-gphoto2 and pySerial for python3 with pip:</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh">sudo pip3 install gphoto2<br>sudo pip3 install pyserial<br></code></pre></td></tr></table></figure><h3 id="Usage-Examples"><a href="#Usage-Examples" class="headerlink" title="Usage Examples"></a>Usage Examples</h3><p>Specify the port and baud rate for the serial communication between Arduino and Raspberry Pi in <code>python/camera.py</code>:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">port = <span class="hljs-string">&#x27;/dev/ttyACM0&#x27;</span><br>baud_rate = <span class="hljs-number">9600</span><br></code></pre></td></tr></table></figure><p>Set the parameters for HDR Light Field capture in <code>python/gui.py</code>:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">camera_name = <span class="hljs-string">&#x27;SonyA7r1&#x27;</span><br><span class="hljs-comment"># hdr_merging = False</span><br></code></pre></td></tr></table></figure><p>(Optional) Merge the captured images into HDR light field (requires OpenCV):</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> merge <span class="hljs-keyword">import</span> merge_light_field<br>merge_light_field(capture_path, camera_name, n_exposures)<br></code></pre></td></tr></table></figure><h2 id="GUI-design-with-python"><a href="#GUI-design-with-python" class="headerlink" title="GUI design with python"></a>GUI design with python</h2><p><img src="gui.jpg"></p><p>GUI allows for basic motor and camera control:</p><ul><li>Motor speed can be set from 1 to 10. (disabled)</li><li>Camera location can range from 0 to 1000.</li><li>Number of exposures and stops can be set according to camera settings.</li><li>Number of views can range from 1 to 1001.</li><li>Click <code>Capture</code> to capture a single image.</li><li>Click <code>Capture LF</code> to capture HDR light field.</li></ul><p>Uncomment relevant code in <code>python/gui.py</code> to enable different controls.</p><h2 id="Release-History"><a href="#Release-History" class="headerlink" title="Release History"></a>Release History</h2><ul><li>0.2.0<ul><li>Edited code structure and added more controls</li><li>CHANGE: Seperate <code>control.py</code> into and <code>control.py</code> and <code>gui.py</code></li></ul></li><li>0.1.0<ul><li>The first proper release</li><li>CHANGE: Add <code>arduino</code> and <code>python</code></li></ul></li><li>0.0.1<ul><li>Work in progress</li></ul></li></ul>]]></content>
    
    
    <categories>
      
      <category>Computer Vision</category>
      
    </categories>
    
    
    <tags>
      
      <tag>IoT</tag>
      
      <tag>Computer graphics</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
